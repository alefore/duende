# DO NOT EDIT. This file is automatically generated by Duende.
import aiofiles
import asyncio
import dataclasses
import logging
import pathlib
import re
import os
import shutil
import subprocess
import tempfile
from typing import Awaitable, Callable, NamedTuple, NewType, Pattern, Sequence

from agent_command import Argument, ArgumentContentType, VariableMap, VariableName, VariableValue
from agent_loop_options import AgentLoopOptions
from agent_loop_options import BaseAgentLoopFactory
from agent_workflow import AgentWorkflow, AgentWorkflowFactory
from agent_workflow_options import AgentWorkflowOptions
from code_specs import FileExtension, MarkerChar, MarkerImplementation, MarkerName, MarkersOverlapError, PathAndValidator, Validator, comment_string, get_markers, prepare_command_registry, prepare_initial_message, relevant_paths_variable, run_agent_loop
from code_specs_commands import ListDuendeMarkerImplementationCommand, UpdateDuendeMarkerImplementationCommand, ReadDuendeImplementationMarkerCommand
from conversation import Conversation, ConversationId, ConversationFactory
from conversation_state import ConversationState
from done_command import DoneCommand, DoneValuesValidator
from list_files_command import ListFilesCommand
from message import Message, ContentSection
from read_file_command import ReadFileCommand
from search_file_command import SearchFileCommand
from validation import ValidationResult
from write_file_command import WriteFileCommand

# A token like "{{" + HEDGEHOG + " " + description + "}}" defines a property for
# which a unit test should be written (validating that the property holds).
HEDGEHOG = MarkerChar("ðŸ¦”")

MUSHROOM = MarkerChar("ðŸ„")

# The full name to a test, including the file in which it is defined (and likely
# the class, if the test is a method in a class). This is returned by `pytest`
# and can be given directly to `pytest` (without the need to add any prefixes).
TestName = NewType("TestName", str)

# Path to a file with unittests.
tests_path_variable = VariableName('tests_path')

PYTEST_BINARY = os.getenv("PYTEST") or "pytest"


class CodeSpecsTestsEnableWorkflow(AgentWorkflow):
  """Starts executing tests gradually, fixing them (or code) until all pass."""

  def __init__(self, options: AgentWorkflowOptions) -> None:
    self._options = options

  async def run(self) -> None:
    input = await self._get_initial_parameters()
    tests = await self._list_tests(input)
    for i in range(len(tests)):
      await self._make_tests_pass(input, tests[0:i + 1])

  async def _list_tests(self, input: pathlib.Path) -> list[TestName]:
    """Uses `pytest` to list all tests in `input`.

    {{ðŸ¦” Returns an empty list on an empty file.}}
    {{ðŸ¦” Returns an empty list on a non-empty file that contains valid python
         code but no tests.}}
    """
    # âœ¨ list tests
    cmd = [PYTEST_BINARY, "--collect-only", "--quiet", str(input)]
    proc = await asyncio.create_subprocess_exec(
        *cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
    stdout, stderr = await proc.communicate()

    if proc.returncode != 0:
      logging.warning(
          f"pytest command failed with exit code {proc.returncode}. "
          f"Stderr: {stderr.decode()}")
      return []

    output_lines = stdout.decode().strip().splitlines()
    tests = [TestName(line) for line in output_lines if line]
    return tests
    # âœ¨

  async def _get_initial_parameters(self) -> pathlib.Path:
    """Obtains the path with tests to enable.

    Calls `run_agent_loop` passing outputs of `prepare_command_registry` and
    `prepare_initial_message`.

    {{ðŸ¦” The only done command argument given to `prepare_command_registry` is
         `tests_path_variable`.}}
    """

    async def done_validator(inputs: VariableMap) -> ValidationResult:
      """Validates that tests_path_variable points to a correct path.

      {{ðŸ¦” Validation fails if the file can't be read.}}
      {{ðŸ¦” Validation fails if the file does not contain any tests (per
           `_list_tests`).}}
      {{ðŸ¦” Validation succeeds if the file can be read.}}
      {{ðŸ¦” Does not require any variables other than `tests_path_variable`.}}
      """
      # âœ¨ initial parameters validator
      path = pathlib.Path(str(inputs[tests_path_variable]))
      if not path.is_file():
        return ValidationResult(
            success=False,
            output="",
            error=f"File '{path}' does not exist or is not a file.")
      try:
        # Check if the file can be read.
        with open(path, 'r') as f:
          pass
      except Exception as e:
        return ValidationResult(
            success=False,
            output="",
            error=f"File '{path}' cannot be read: {e}")

      tests = await self._list_tests(path)
      if not tests:
        return ValidationResult(
            success=False, output="", error=f"File '{path}' contains no tests.")

      return ValidationResult(
          success=True, output="Validation successful.", error="")
      # âœ¨

    start_message_content = (
        "GOAL: Ask the user (through text conversation) "
        "for approprivate values "
        "for the variables expected by `done`. "
        "Describe these variables to the user "
        "to help them understand what is expected."
        "\n"
        "If the user mentions a file that doesn't exist, "
        "try to look for likely typos in their input. "
        "Try also to list files in the directory "
        "to see if you can guess what the user may have meant."
        "\n"
        "Once the user has given you appropriate values, "
        "your goal is achieved and you should run `done`.")
    # âœ¨ initial parameters
    done_command_arguments = [
        Argument(
            name=tests_path_variable,
            arg_type=ArgumentContentType.PATH_INPUT,
            description="Path to the file containing tests.")
    ]
    command_registry = await prepare_command_registry(
        done_command_arguments=done_command_arguments,
        done_validator_callback=done_validator,
        file_access_policy=self._options.agent_loop_options.file_access_policy)

    initial_message = await prepare_initial_message(
        start_message_content=start_message_content, relevant_files=set())

    output_variables = await run_agent_loop(
        workflow_options=self._options,
        conversation_name="get_initial_parameters",
        start_message=initial_message,
        command_registry=command_registry)

    return pathlib.Path(str(output_variables[tests_path_variable]))
    # âœ¨

  async def _run_tests(self, tests: list[TestName]) -> str | None:
    """Runs the tests given and returns an optional string with failure info.

    {{ðŸ¦” If all tests listed in `tests` pass, returns None.}}
    {{ðŸ¦” If at least one test (from `tests`) fails, returns a string with a
         description of the failures.}}
    {{ðŸ¦” Only runs the tests listed in `tests`; additional tests in `input` do
         not run.}}
    """
    # âœ¨ run tests
    if not tests:
      return None  # No tests to run, so all pass.

    cmd = [PYTEST_BINARY] + [str(test) for test in tests]
    proc = await asyncio.create_subprocess_exec(
        *cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
    stdout, stderr = await proc.communicate()

    if proc.returncode == 0:
      return None  # All tests passed.
    else:
      # Return a string with a description of the failures.
      # We combine stdout and stderr for a complete picture.
      output = stdout.decode() + stderr.decode()
      return f"Tests failed with exit code {proc.returncode}:\n{output}"
    # âœ¨

  async def _find_relevant_paths(
      self, input: pathlib.Path,
      tests: list[TestName]) -> dict[TestName, set[pathlib.Path]]:
    """Finds all relevant paths for all tests.

    {{ðŸ¦” Calls `find_relevant_paths_for_test` exactly once for value in
         `tests`.}}
    {{ðŸ¦” Calls to `find_relevant_paths_for_test` happen concurrently.}}
    {{ðŸ¦” The output keys are the same as the `tests` input.}}
    {{ðŸ¦” The output values correspond to the outputs of
         `_find_relevant_paths_for_test` for each key (test).}}
    """
    # âœ¨ find relevant paths loop
    tasks = []
    for test in tests:
      tasks.append(self._find_relevant_paths_for_test(input, test))

    results = await asyncio.gather(*tasks)

    # Combine tests and their corresponding relevant paths into a dictionary
    relevant_paths_map = {}
    for test, paths in zip(tests, results):
      relevant_paths_map[test] = paths

    return relevant_paths_map
    # âœ¨

  async def _find_relevant_paths_for_test(self, input: pathlib.Path,
                                          test: TestName) -> set[pathlib.Path]:
    """Finds all relevant paths to validate a test's implementation.

    Calls `run_agent_loop` passing outputs of `prepare_command_registry` and
    `prepare_initial_message`. The agent is focused exclusively on `test`,
    with the goal of identifying the best value for `relevant_paths_variable`.

    {{ðŸ¦” The only done command argument given to `prepare_command_registry` is
         `relevant_paths_variable`.}}
    """

    async def done_validate(inputs: VariableMap) -> ValidationResult:
      """Verifies that all inputs[relevant_paths_variable] values are readable.

      {{ðŸ¦” If no files are given, validation fails, with a message that at least
           one relevant file should be given.}}
      {{ðŸ¦” All files must be readable (both by the OS as well as allowed by the
           `file_access_policy`). If one isn't, validation fails.}}
      {{ðŸ¦” If all files are readable (both by the OS and `file_access_policy`),
           validation succeeds.}}
      """
      # âœ¨ relevant paths validator
      relevant_paths_raw = inputs.get(relevant_paths_variable)
      if not relevant_paths_raw:
        return ValidationResult(
            success=False,
            output="",
            error=f"At least one relevant file path must be provided for "
            f"'{relevant_paths_variable}'.")

      # Ensure relevant_paths_raw is treated as a string, as per expected input format
      relevant_paths_str = str(relevant_paths_raw)
      paths = [
          pathlib.Path(p.strip())
          for p in relevant_paths_str.split(',')
          if p.strip()
      ]

      if not paths:
        return ValidationResult(
            success=False,
            output="",
            error=f"At least one relevant file path must be provided for "
            f"'{relevant_paths_variable}'.")

      file_access_policy = self._options.agent_loop_options.file_access_policy
      for path in paths:
        if not path.is_file():
          return ValidationResult(
              success=False,
              output="",
              error=f"File '{path}' does not exist or is not a file.")
        if not os.access(path, os.R_OK):
          return ValidationResult(
              success=False,
              output="",
              error=f"File '{path}' is not readable by the operating system.")
        if not file_access_policy.allow_access(str(path)):
          return ValidationResult(
              success=False,
              output="",
              error=f"File '{path}' is not allowed by the file access policy.")

      return ValidationResult(
          success=True, output="Validation successful.", error="")
      # âœ¨

    start_message_content = (
        f"GOAL: identify local file paths that are relevant "
        f"to understand the test \"{test}\", "
        f"including the implementation of the underlying logic under test. "
        f"The test is defined in file {input} "
        f"(likely among many other tests that you should ignore)."
        f"\n"
        f"These relevant paths should be given to the "
        f"`{relevant_paths_variable}` argument of the `done` command."
        f"\n"
        f"Example: `done(relevant_paths=\"src/foo.py,src/bar.cc\")"
        f"\n"
        f"Feel free to use `read_file`, `list_files` and `search_file` "
        f"to explore the codebase.")
    # âœ¨ find relevant paths
    done_command_arguments = [
        Argument(
            name=relevant_paths_variable,
            arg_type=ArgumentContentType.STRING,
            description="Comma-separated list of relevant file paths.")
    ]
    command_registry = await prepare_command_registry(
        done_command_arguments=done_command_arguments,
        done_validator_callback=done_validate,
        file_access_policy=self._options.agent_loop_options.file_access_policy)

    initial_message = await prepare_initial_message(
        start_message_content=start_message_content, relevant_files=set())

    output_variables = await run_agent_loop(
        workflow_options=self._options,
        conversation_name=f"find_relevant_paths_for_test_{test}",
        start_message=initial_message,
        command_registry=command_registry)

    relevant_paths_raw = output_variables[relevant_paths_variable]
    relevant_paths_str = str(relevant_paths_raw)
    paths = {
        pathlib.Path(p.strip())
        for p in relevant_paths_str.split(',')
        if p.strip()
    }
    return paths
    # âœ¨

  async def _make_tests_pass(self, input, tests: list[TestName]) -> None:
    """Runs an agent to fix any failing  tests (from `tests`).

    Calls `run_agent_loop`.

    {{ðŸ¦” If all tests already pass (when this is called), no agent is created.}}
    {{ðŸ¦” If at least one test is failing (when this is called), runs an agent.}}
    {{ðŸ¦” If an agent is run, it is given an initial prompt that includes the
         failure information (output of `_run_tests`).}}
    {{ðŸ¦” If an agent is run, it receives `input` in `relevant_files`.}}
    {{ðŸ¦” No `done` command argument is given to `prepare_command_registry`.}}
    {{ðŸ¦” The command registry given to the agent includes `WriteFileCommand`.}}
    {{ðŸ¦” The command registry given to the agent includes
         `ListDuendeMarkerImplementationCommand`.}}
    {{ðŸ¦” The command registry given to the agent includes
         `ListDuendeMarkerImplementationCommand`,
         `UpdateDuendeMarkerImplementationCommand`, and
         `ReadDuendeImplementationMarkerCommand`.}}
    {{ðŸ¦” The name of the conversation does *not* include the test names, because
         that's too verbose. Instead, it includes the number of tests in
         scope (i.e., `len(tests)`).}}
    """

    async def done_validator(inputs: VariableMap) -> ValidationResult:
      """Validates that all tests in `tests` pass.

      {{ðŸ¦” Validation fails if at least one test (from `tests`) doesn't pass.}}
      {{ðŸ¦” Validation succeeds if all tests (from `tests`) pass.}}
      {{ðŸ¦” Validation doesn't depend on `inputs`.}}
      {{ðŸ¦” If validation fails, all information about the failures is given in
           the output (to help the AI understand what's missing).}}
      """
      # âœ¨ make tests pass validator
      failure_info = await self._run_tests(tests)
      if failure_info:
        return ValidationResult(
            success=False, output=failure_info, error="Not all tests passed.")
      return ValidationResult(
          success=True, output="All tests passed.", error="")
      # âœ¨

    start_message_content = (
        "GOAL: Make unit tests pass. "
        "To do this, first determine "
        "whether the problem is in the failing tests "
        "or in the implementation. "
        "Give an explanation in English to support your conclusion. "
        "Then adjust the root cause of the problem and call `done`.\n"
        "As much as possible, "
        "prefer using `update_duende_marker_implementation` "
        "in order to update blocks "
        "(rather than writing entire files).\n"
        "Calling `done` will cause the tests in scope to be executed "
        "and will confirm that you've successfully fixed the problem.\n"
        "We may not be executing all tests but only a subset. That's OK. "
        "You should focus only on fixing the explicit failures.\n")

    # âœ¨ make tests pass
    failure_info = await self._run_tests(tests)
    if not failure_info:
      logging.info("All tests already pass, no agent run for _make_tests_pass.")
      return

    # The start_message_content for the agent.
    # It combines the base message with the current failure information.
    start_message_content += (
        f"\nThe following tests are failing:\n```\n{failure_info}\n```")

    # The done_validator for this agent is already defined above in this file.
    # It's an inner function to _make_tests_pass, so it captures 'self' and 'tests'.
    command_registry = await prepare_command_registry(
        done_command_arguments=[],
        done_validator_callback=done_validator,  # Refers to the async def done_validator defined previously in the file.
        file_access_policy=self._options.agent_loop_options.file_access_policy)

    # Register WriteFileCommand to allow the agent to modify files.
    write_file_command = WriteFileCommand(
        validation_manager=self._options.agent_loop_options.validation_manager,
        selection_manager=self._options.selection_manager,
        hard_coded_path=None)
    command_registry.Register(write_file_command)

    # Register Duende marker commands.
    list_duende_marker_implementation_command = ListDuendeMarkerImplementationCommand(
        file_access_policy=self._options.agent_loop_options.file_access_policy,
        validation_manager=self._options.agent_loop_options.validation_manager)
    command_registry.Register(list_duende_marker_implementation_command)

    read_duende_implementation_marker_command = ReadDuendeImplementationMarkerCommand(
        file_access_policy=self._options.agent_loop_options.file_access_policy,
        validation_manager=self._options.agent_loop_options.validation_manager)
    command_registry.Register(read_duende_implementation_marker_command)

    update_duende_marker_implementation_command = UpdateDuendeMarkerImplementationCommand(
        file_access_policy=self._options.agent_loop_options.file_access_policy,
        validation_manager=self._options.agent_loop_options.validation_manager)
    command_registry.Register(update_duende_marker_implementation_command)

    # Prepare the initial message for the agent loop, including relevant files.
    # The 'input' here is the path to the test file.
    initial_message = await prepare_initial_message(
        start_message_content=start_message_content, relevant_files={input})

    # Construct the conversation name based on the number of tests.
    conversation_name = f"make_tests_pass_{len(tests)}"

    # Run the agent loop.
    await run_agent_loop(
        workflow_options=self._options,
        conversation_name=conversation_name,
        start_message=initial_message,
        command_registry=command_registry)
    # âœ¨


class CodeSpecsTestsEnableWorkflowFactory(AgentWorkflowFactory):

  def name(self) -> str:
    return "dm-tests-enable"

  async def new(self, agent_workflow_options: AgentWorkflowOptions,
                args: dict[str, str]) -> AgentWorkflow:
    return CodeSpecsTestsEnableWorkflow(agent_workflow_options)