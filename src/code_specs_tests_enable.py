# DO NOT EDIT. This file is automatically generated by Duende.
import aiofiles
import asyncio
import dataclasses
import logging
import pathlib
import re
import os
import shutil
import subprocess
import tempfile
from typing import Awaitable, Callable, NamedTuple, NewType, Pattern, Sequence

from agent_command import Argument, ArgumentContentType, VariableMap, VariableName, VariableValue
from agent_loop_options import AgentLoopOptions
from agent_loop_options import BaseAgentLoopFactory
from agent_workflow import AgentWorkflow, AgentWorkflowFactory
from agent_workflow_options import AgentWorkflowOptions
from ask_command import AskCommand
from code_specs import FileExtension, MarkerChar, MarkerImplementation, MarkerName, MarkersOverlapError, PathAndValidator, Validator, comment_string, get_markers, prepare_command_registry, prepare_initial_message, relevant_paths_variable, run_agent_loop
from code_specs_commands import ListDuendeMarkerImplementationCommand, UpdateDuendeMarkerImplementationCommand, ReadDuendeImplementationMarkerCommand
from conversation import Conversation, ConversationId, ConversationFactory
from conversation_state import ConversationState
from done_command import DoneCommand, DoneValuesValidator
from list_files_command import ListFilesCommand
from message import Message, ContentSection
from read_file_command import ReadFileCommand
from search_file_command import SearchFileCommand
from validation import ValidationResult
from write_file_command import WriteFileCommand

# A token like "{{" + HEDGEHOG + " " + description + "}}" defines a property for
# which a unit test should be written (validating that the property holds).
HEDGEHOG = MarkerChar("ðŸ¦”")

MUSHROOM = MarkerChar("ðŸ„")

# The full name to a test, including the file in which it is defined (and likely
# the class, if the test is a method in a class). This is returned by `pytest`
# and can be given directly to `pytest` (without the need to add any prefixes).
TestName = NewType("TestName", str)

# Path to a file with unittests.
tests_path_variable = VariableName('tests_path')

PYTEST_BINARY = os.getenv("PYTEST") or "pytest"


class CodeSpecsTestsEnableWorkflow(AgentWorkflow):
  """Starts executing tests gradually, fixing them (or code) until all pass."""

  def __init__(self, options: AgentWorkflowOptions) -> None:
    self._options = options

  async def run(self) -> None:
    input = await self._get_initial_parameters()
    tests = await self._list_tests(input)
    for i in range(len(tests)):
      await self._make_tests_pass(input, tests[0:i + 1])

  async def _list_tests(self, input: pathlib.Path) -> list[TestName]:
    """Uses `pytest` to list all tests in `input`.

    {{ðŸ¦” Returns an empty list on an empty file.}}
    {{ðŸ¦” Returns an empty list on a non-empty file that contains valid python
         code but no tests.}}
    """

    # âœ¨ list tests
    cmd = [PYTEST_BINARY, "--collect-only", "--quiet", str(input)]
    proc = await asyncio.create_subprocess_exec(
        *cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
    stdout, stderr = await proc.communicate()

    if proc.returncode != 0:
      logging.warning(
          f"pytest command failed with exit code {proc.returncode}. "
          f"Stderr: {stderr.decode()}")
      return []

    output_lines = stdout.decode().strip().splitlines()
    tests = [TestName(line) for line in output_lines if line]
    return tests
    # âœ¨

  async def _get_initial_parameters(self) -> pathlib.Path:
    """Obtains the path with tests to enable.

    Calls `run_agent_loop` passing outputs of `prepare_command_registry` and
    `prepare_initial_message`.

    {{ðŸ¦” The only done command argument given to `prepare_command_registry` is
         `tests_path_variable`.}}
    """

    async def done_validator(inputs: VariableMap) -> ValidationResult:
      """Validates that tests_path_variable points to a correct path.

      {{ðŸ¦” Validation fails if the file can't be read.}}
      {{ðŸ¦” Validation fails if the file does not contain any tests (per
           `_list_tests`).}}
      {{ðŸ¦” Validation succeeds if the file can be read.}}
      {{ðŸ¦” Does not require any variables other than `tests_path_variable`.}}
      """
      # âœ¨ initial parameters validator
      path = pathlib.Path(str(inputs[tests_path_variable]))
      if not path.is_file():
        return ValidationResult(
            success=False,
            output="",
            error=f"File '{path}' does not exist or is not a file.")
      try:
        # Check if the file can be read.
        with open(path, 'r') as f:
          pass
      except Exception as e:
        return ValidationResult(
            success=False,
            output="",
            error=f"File '{path}' cannot be read: {e}")

      tests = await self._list_tests(path)
      if not tests:
        return ValidationResult(
            success=False, output="", error=f"File '{path}' contains no tests.")

      return ValidationResult(
          success=True, output="Validation successful.", error="")
      # âœ¨

    start_message_content = (
        "GOAL: Ask the user (through text conversation) "
        "for approprivate values "
        "for the variables expected by `done`. "
        "Describe these variables to the user "
        "to help them understand what is expected."
        "\n"
        "If the user mentions a file that doesn't exist, "
        "try to look for likely typos in their input. "
        "Try also to list files in the directory "
        "to see if you can guess what the user may have meant."
        "\n"
        "Once the user has given you appropriate values, "
        "your goal is achieved and you should run `done`.")
    # âœ¨ initial parameters
    done_command_arguments = [
        Argument(
            name=tests_path_variable,
            arg_type=ArgumentContentType.PATH_INPUT,
            description="Path to the file containing tests.")
    ]
    command_registry = await prepare_command_registry(
        done_command_arguments=done_command_arguments,
        done_validator_callback=done_validator,
        file_access_policy=self._options.agent_loop_options.file_access_policy)

    initial_message = await prepare_initial_message(
        start_message_content=start_message_content, relevant_files=set())

    output_variables = await run_agent_loop(
        workflow_options=self._options,
        conversation_name="get_initial_parameters",
        start_message=initial_message,
        command_registry=command_registry)

    return pathlib.Path(str(output_variables[tests_path_variable]))
    # âœ¨

  async def _run_tests(self, tests: list[TestName]) -> str | None:
    """Runs the tests given and returns an optional string with failure info.

    {{ðŸ¦” If all tests listed in `tests` pass, returns None.}}
    {{ðŸ¦” If at least one test (from `tests`) fails, returns a string with a
         description of the failures.}}
    {{ðŸ¦” Only runs the tests listed in `tests`; additional tests in `input` do
         not run.}}
    """
    # âœ¨ run tests
    if not tests:
      return None  # No tests to run, so all pass.

    cmd = [PYTEST_BINARY] + [str(test) for test in tests]
    proc = await asyncio.create_subprocess_exec(
        *cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
    stdout, stderr = await proc.communicate()

    if proc.returncode == 0:
      return None  # All tests passed.
    else:
      # Return a string with a description of the failures.
      # We combine stdout and stderr for a complete picture.
      output = stdout.decode() + stderr.decode()
      return f"Tests failed with exit code {proc.returncode}:\n{output}"
    # âœ¨

  async def _make_tests_pass(self, input: pathlib.Path,
                             tests: list[TestName]) -> None:
    """Runs an agent to fix any failing  tests (from `tests`).

    Calls `run_agent_loop`.

    {{ðŸ¦” If all tests already pass (when this is called), no agent is created.}}
    {{ðŸ¦” If at least one test is failing (when this is called), runs an agent.}}
    {{ðŸ¦” If an agent is run, it is given an initial prompt that includes the
         failure information (output of `_run_tests`).}}
    {{ðŸ¦” If an agent is run, it receives `input` in `relevant_files`.}}
    {{ðŸ¦” No `done` command argument is given to `prepare_command_registry`.}}
    {{ðŸ¦” The command registry given to the agent includes `WriteFileCommand`.}}
    {{ðŸ¦” The command registry given to the agent includes
         `ListDuendeMarkerImplementationCommand`.}}
    {{ðŸ¦” The command registry given to the agent includes:
         * `ListDuendeMarkerImplementationCommand`
         * `UpdateDuendeMarkerImplementationCommand`
         * `ReadDuendeImplementationMarkerCommand`
         * `AskCommand`}}
    {{ðŸ¦” The name of the conversation includes `len(tests)` followed by the last
         value in `tests`.}}
    """

    async def done_validator(inputs: VariableMap) -> ValidationResult:
      """Validates that all tests in `tests` pass.

      {{ðŸ¦” Validation fails if at least one test (from `tests`) doesn't pass.}}
      {{ðŸ¦” Validation succeeds if all tests (from `tests`) pass.}}
      {{ðŸ¦” Validation doesn't depend on `inputs`.}}
      {{ðŸ¦” If validation fails, all information about the failures is given in
           the output (to help the AI understand what's missing).}}
      """
      # âœ¨ make tests pass validator
      failure_info = await self._run_tests(tests)
      if failure_info:
        return ValidationResult(
            success=False, output=failure_info, error="Not all tests passed.")
      return ValidationResult(
          success=True, output="All tests passed.", error="")
      # âœ¨

    start_message_content = (
        "GOAL: Make unit tests pass. "
        "To do this, first determine "
        "whether the problem is in the failing tests "
        "or in the implementation. "
        "Give an explanation in English to support your conclusion. "
        "Then adjust the root cause of the problem and call `done`.\n"
        "As much as possible, "
        "prefer using `update_duende_marker_implementation` "
        "in order to update blocks "
        "(rather than writing entire files).\n"
        "Calling `done` will cause the tests in scope to be executed "
        "and will confirm that you've successfully fixed the problem.\n"
        "We may not be executing all tests but only a subset. That's OK. "
        "You should focus only on fixing the explicit failures.\n"
        "Avoid loading too much information: "
        "prefer using `ask` to fork other conversations "
        "that figure out the answer to specific questions.")
    # âœ¨ make tests pass
    failure_info = await self._run_tests(tests)
    if not failure_info:
      logging.info("All tests already pass, no agent run for _make_tests_pass.")
      return

    # The start_message_content for the agent.
    # It combines the base message with the current failure information.
    start_message_content += (
        f"\nThe following tests are failing:\n```\n{failure_info}\n```")

    # The done_validator for this agent is already defined above in this file.
    # It's an inner function to _make_tests_pass, so it captures 'self' and 'tests'.
    command_registry = await prepare_command_registry(
        done_command_arguments=[],
        done_validator_callback=done_validator,  # Refers to the async def done_validator defined previously in the file.
        file_access_policy=self._options.agent_loop_options.file_access_policy)

    # Register WriteFileCommand to allow the agent to modify files.
    write_file_command = WriteFileCommand(
        validation_manager=self._options.agent_loop_options.validation_manager,
        selection_manager=self._options.selection_manager,
        hard_coded_path=None)
    command_registry.Register(write_file_command)

    # Register Duende marker commands.
    list_duende_marker_implementation_command = ListDuendeMarkerImplementationCommand(
        file_access_policy=self._options.agent_loop_options.file_access_policy,
        validation_manager=self._options.agent_loop_options.validation_manager)
    command_registry.Register(list_duende_marker_implementation_command)

    read_duende_implementation_marker_command = ReadDuendeImplementationMarkerCommand(
        file_access_policy=self._options.agent_loop_options.file_access_policy,
        validation_manager=self._options.agent_loop_options.validation_manager)
    command_registry.Register(read_duende_implementation_marker_command)

    update_duende_marker_implementation_command = UpdateDuendeMarkerImplementationCommand(
        file_access_policy=self._options.agent_loop_options.file_access_policy,
        validation_manager=self._options.agent_loop_options.validation_manager)
    command_registry.Register(update_duende_marker_implementation_command)

    # Register AskCommand to allow the agent to fork conversations.
    ask_command = AskCommand(
        conversation_factory=self._options.conversation_factory,
        conversational_ai=self._options.agent_loop_options.conversational_ai,
        confirmation_state=self._options.agent_loop_options.confirmation_state,
        file_access_policy=self._options.agent_loop_options.file_access_policy,
        command_registry=command_registry,
        validation_manager=self._options.agent_loop_options.validation_manager,
        confirm_regex=self._options.agent_loop_options.confirm_regex)
    command_registry.Register(ask_command)

    # Prepare the initial message for the agent loop, including relevant files.
    # The 'input' here is the path to the test file.
    initial_message = await prepare_initial_message(
        start_message_content=start_message_content, relevant_files=set())

    # Construct the conversation name based on the number of tests.
    conversation_name = f"make_tests_pass_{len(tests)}_{tests[-1]}"

    # Run the agent loop.
    await run_agent_loop(
        workflow_options=self._options,
        conversation_name=conversation_name,
        start_message=initial_message,
        command_registry=command_registry)
    # âœ¨


class CodeSpecsTestsEnableWorkflowFactory(AgentWorkflowFactory):

  def name(self) -> str:
    return "dm-tests-enable"

  async def new(self, agent_workflow_options: AgentWorkflowOptions,
                args: dict[str, str]) -> AgentWorkflow:
    return CodeSpecsTestsEnableWorkflow(agent_workflow_options)