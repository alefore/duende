# DO NOT EDIT. This file is automatically generated by Duende.
# DM validator:
# MYPYPATH=~/coding-agent/src mypy $DMPATH && grep -v mo""ck $DMPATH
#
# Mock is NOT allowed in this code. These tests should let all the dependencies
# of CodeSpecsTestsSkeleton be used directly.

import aiofiles
from collections import defaultdict
import os
import pathlib
import re
import tempfile
from typing import Callable, Awaitable, Any
import unittest

from agent_command import Argument, AgentCommand, CommandOutput, CommandInput, AgentCommand, VariableMap, VariableName, VariableValue, VariableValueStr
from agent_loop import AgentLoop, AgentLoopFactory
from agent_loop_options import AgentLoopOptions, BaseAgentLoop, BaseAgentLoopFactory
from agent_workflow_options import AgentWorkflowOptions
from code_specs import PathAndValidator, Validator, prepare_command_registry, prepare_initial_message, run_agent_loop, ValidationResult, MarkerChar, MarkersOverlapError, MarkerName
from code_specs_tests_skeleton import CodeSpecsTestsSkeletonWorkflow, tests_skeleton_variable, MUSHROOM, HEDGEHOG, path_to_test_variable
from command_registry import CommandRegistry
from confirmation import ConfirmationManager, ConfirmationState
from conversation import Conversation, ConversationId, ConversationFactory, ConversationFactoryOptions
from conversation_state import ConversationState
from conversational_ai import ConversationalAI
from conversational_ai_test_utils import FakeConversationalAIConversation, FakeConversationalAI
from done_command import DoneCommand
from file_access_policy import FileAccessPolicy
from message import ContentSection, Message
from selection_manager import SelectionManager


class TestFileAccessPolicy(FileAccessPolicy):

  def allow_access(self, path: str) -> bool:
    return True  # Allow all access for testing


class TestConfirmationState(ConfirmationState):

  async def RequireConfirmation(self, conversation_id: int,
                                prompt: str) -> str | None:
    return None


class TestConfirmationManager(ConfirmationManager):

  async def RequireConfirmation(self, conversation_id: ConversationId,
                                message: str) -> str | None:
    return None


class TestSelectionManager(SelectionManager):
  pass  # Default implementation is fine for now


class TestCodeSpecsTestsSkeletonWorkflow(unittest.IsolatedAsyncioTestCase):

  async def test_get_initial_parameters_only_path_to_test_variable_argument(
      self) -> None:
    # âœ¨ The only done command argument given to `prepare_command_registry` is `path_to_test_variable`.
    # Instantiate dependencies
    file_access_policy = TestFileAccessPolicy()
    confirmation_manager = TestConfirmationManager()
    selection_manager = TestSelectionManager()

    conversation_factory_options = ConversationFactoryOptions()
    conversation_factory = ConversationFactory(conversation_factory_options)

    # Create a dummy path for the done command output.
    dummy_path = pathlib.Path("/tmp/fake_test_file.py")

    # There's a bug here: we should actually write a temporary file (and not
    # assume it is /tmp/fake_test_file.py) so that the validation passes and
    # the AgentLoop returns.

    # Prepare scripted responses for FakeConversationalAI
    scripted_responses_for_initial_parameters = defaultdict(
        list,
        {
            "initial_parameters": [
                Message(
                    role="assistant",
                    content_sections=[
                        ContentSection(
                            content="",  # Must provide content, even if empty
                            command=CommandInput(
                                command_name="done",
                                args=VariableMap({
                                    path_to_test_variable:
                                        VariableValueStr(str(dummy_path))
                                })))
                    ])
            ]
        })
    conversational_ai = FakeConversationalAI(
        scripted_responses=scripted_responses_for_initial_parameters)

    # Setup AgentLoopOptions
    # `conversation` and `commands_registry` here are placeholders.
    # The `run_agent_loop` function will create a new conversation and registry
    # within its scope using the factories and `prepare_command_registry`.
    agent_loop_options = AgentLoopOptions(
        conversation=conversation_factory.New(
            name="initial_parameters_dummy",
            command_registry=CommandRegistry()),
        start_message=Message(
            role="user", content_sections=[ContentSection(content="")]),
        commands_registry=CommandRegistry(
        ),  # Will be replaced by prepare_command_registry
        confirmation_state=ConfirmationState(
            confirmation_manager=confirmation_manager),
        file_access_policy=file_access_policy,
        conversational_ai=conversational_ai,
        skip_implicit_validation=True,
    )

    # Setup AgentWorkflowOptions using the real AgentLoopFactory
    workflow_options = AgentWorkflowOptions(
        agent_loop_options=agent_loop_options,
        agent_loop_factory=AgentLoopFactory(),  # Use the real factory
        conversation_factory=conversation_factory,
        selection_manager=selection_manager,
    )

    workflow = CodeSpecsTestsSkeletonWorkflow(workflow_options)

    await workflow._get_initial_parameters()

    # After `_get_initial_parameters` runs, a conversation named "initial_parameters"
    # should have been created and processed by `run_agent_loop`.
    # The conversation_factory will hold a reference to it.
    conversations = conversation_factory.GetAll()
    self.assertEqual(
        len(conversations), 1,
        "Expected exactly one conversation to be created.")
    last_conversation = conversations[0]
    self.assertEqual(
        last_conversation.GetName(), "initial_parameters",
        "The created conversation should be named 'initial_parameters'.")

    # Assert that the command_registry contains the DoneCommand with the correct arguments
    registry = last_conversation.command_registry
    done_command = registry.Get("done")
    self.assertIsNotNone(
        done_command,
        "DoneCommand should be registered in the command registry.")
    assert done_command is not None

    done_syntax = done_command.Syntax()
    actual_args = done_syntax.arguments

    self.assertEqual(
        len(actual_args), 1,
        "Expected exactly one argument for the done command.")
    self.assertEqual(actual_args[0].name, path_to_test_variable,
                     "The argument name should be path_to_test_variable.")
    # âœ¨

  async def test_initial_parameters_validator_fails_if_file_cant_be_read(
      self) -> None:
    # âœ¨ Validation fails if the file can't be read.
    # Instantiate dependencies
    file_access_policy = TestFileAccessPolicy()
    confirmation_manager = TestConfirmationManager()
    selection_manager = TestSelectionManager()

    conversation_factory_options = ConversationFactoryOptions()
    conversation_factory = ConversationFactory(conversation_factory_options)

    # Create a dummy path to a non-existent file for the done command output.
    non_existent_path = pathlib.Path("/tmp/non_existent_file_for_test.py")

    # Prepare scripted responses for FakeConversationalAI
    scripted_responses_for_initial_parameters = defaultdict(
        list,
        {
            "initial_parameters": [
                Message(
                    role="assistant",
                    content_sections=[
                        ContentSection(
                            content="",  # Must provide content, even if empty
                            command=CommandInput(
                                command_name="done",
                                args=VariableMap({
                                    path_to_test_variable:
                                        VariableValueStr(
                                            str(non_existent_path))
                                })))
                    ])
            ]
        })
    conversational_ai = FakeConversationalAI(
        scripted_responses=scripted_responses_for_initial_parameters)

    # Setup AgentLoopOptions
    agent_loop_options = AgentLoopOptions(
        conversation=conversation_factory.New(
            name="initial_parameters_dummy",
            command_registry=CommandRegistry()),
        start_message=Message(
            role="user", content_sections=[ContentSection(content="")]),
        commands_registry=CommandRegistry(),
        confirmation_state=ConfirmationState(
            confirmation_manager=confirmation_manager),
        file_access_policy=file_access_policy,
        conversational_ai=conversational_ai,
        skip_implicit_validation=True,
    )

    # Setup AgentWorkflowOptions
    workflow_options = AgentWorkflowOptions(
        agent_loop_options=agent_loop_options,
        agent_loop_factory=AgentLoopFactory(),
        conversation_factory=conversation_factory,
        selection_manager=selection_manager,
    )

    workflow = CodeSpecsTestsSkeletonWorkflow(workflow_options)

    # We expect the validation to fail, so _get_initial_parameters should raise an exception
    with self.assertRaisesRegex(ValueError, "Cannot read file"):
      await workflow._get_initial_parameters()
    # âœ¨

  async def test_initial_parameters_validator_fails_if_no_hedgehog_markers(
      self) -> None:
    # âœ¨ Validation fails if the file doesn't contain any HEDGEHOG markers (per `code_specs.get_markers`).
    # Instantiate dependencies
    file_access_policy = TestFileAccessPolicy()
    confirmation_manager = TestConfirmationManager()
    selection_manager = TestSelectionManager()

    conversation_factory_options = ConversationFactoryOptions()
    conversation_factory = ConversationFactory(conversation_factory_options)

    # Create a temporary file with no HEDGEHOG markers
    with tempfile.TemporaryDirectory() as tmpdir:
      temp_file_path = pathlib.Path(tmpdir) / "file_without_markers.py"
      # Write some content, but no HEDGEHOG markers
      with open(temp_file_path, "w") as f:
        f.write("def foo():\n  return 'bar'\n")

      # Prepare scripted responses for FakeConversationalAI
      scripted_responses_for_initial_parameters = defaultdict(
          list,
          {
              "initial_parameters": [
                  Message(
                      role="assistant",
                      content_sections=[
                          ContentSection(
                              content="",  # Must provide content, even if empty
                              command=CommandInput(
                                  command_name="done",
                                  args=VariableMap({
                                      path_to_test_variable:
                                          VariableValueStr(str(temp_file_path))
                                  })))
                      ])
              ]
          })
      conversational_ai = FakeConversationalAI(
          scripted_responses=scripted_responses_for_initial_parameters)

      # Setup AgentLoopOptions
      agent_loop_options = AgentLoopOptions(
          conversation=conversation_factory.New(
              name="initial_parameters_dummy",
              command_registry=CommandRegistry()),
          start_message=Message(
              role="user", content_sections=[ContentSection(content="")]),
          commands_registry=CommandRegistry(),
          confirmation_state=ConfirmationState(
              confirmation_manager=confirmation_manager),
          file_access_policy=file_access_policy,
          conversational_ai=conversational_ai,
          skip_implicit_validation=True,
      )

      # Setup AgentWorkflowOptions
      workflow_options = AgentWorkflowOptions(
          agent_loop_options=agent_loop_options,
          agent_loop_factory=AgentLoopFactory(),
          conversation_factory=conversation_factory,
          selection_manager=selection_manager,
      )

      workflow = CodeSpecsTestsSkeletonWorkflow(workflow_options)

      # We expect the validation to fail because no HEDGEHOG markers are found.
      with self.assertRaisesRegex(
          ValueError,
          f"File '{temp_file_path}' does not contain any '{HEDGEHOG}' markers."
      ):
        await workflow._get_initial_parameters()
    # âœ¨

  async def test_initial_parameters_validator_succeeds_with_readable_file_and_hedgehog_markers(
      self) -> None:
    # âœ¨ Validation succeeds if the file can be read and contains HEDGEHOG markers (per `code_specs.get_markers`).
    # Instantiate dependencies
    file_access_policy = TestFileAccessPolicy()
    confirmation_manager = TestConfirmationManager()
    selection_manager = TestSelectionManager()

    conversation_factory_options = ConversationFactoryOptions()
    conversation_factory = ConversationFactory(conversation_factory_options)

    # Create a temporary file with HEDGEHOG markers
    with tempfile.TemporaryDirectory() as tmpdir:
      temp_file_path = pathlib.Path(tmpdir) / "file_with_hedgehog_markers.py"
      # Write some content with HEDGEHOG markers
      with open(temp_file_path, "w") as f:
        f.write("def func_with_prop():\n")
        f.write("  pass  # {{ðŸ¦” A property of func_with_prop}}\n")
        f.write("def another_func():\n")
        f.write("  return True\n")

      # Prepare scripted responses for FakeConversationalAI
      scripted_responses_for_initial_parameters = defaultdict(
          list,
          {
              "initial_parameters": [
                  Message(
                      role="assistant",
                      content_sections=[
                          ContentSection(
                              content="",  # Must provide content, even if empty
                              command=CommandInput(
                                  command_name="done",
                                  args=VariableMap({
                                      path_to_test_variable:
                                          VariableValueStr(str(temp_file_path))
                                  })))
                      ])
              ]
          })
      conversational_ai = FakeConversationalAI(
          scripted_responses=scripted_responses_for_initial_parameters)

      # Setup AgentLoopOptions
      agent_loop_options = AgentLoopOptions(
          conversation=conversation_factory.New(
              name="initial_parameters_dummy",
              command_registry=CommandRegistry()),
          start_message=Message(
              role="user", content_sections=[ContentSection(content="")]),
          commands_registry=CommandRegistry(),
          confirmation_state=ConfirmationState(
              confirmation_manager=confirmation_manager),
          file_access_policy=file_access_policy,
          conversational_ai=conversational_ai,
          skip_implicit_validation=True,
      )

      # Setup AgentWorkflowOptions
      workflow_options = AgentWorkflowOptions(
          agent_loop_options=agent_loop_options,
          agent_loop_factory=AgentLoopFactory(),
          conversation_factory=conversation_factory,
          selection_manager=selection_manager,
      )

      workflow = CodeSpecsTestsSkeletonWorkflow(workflow_options)

      # We expect the validation to succeed, so _get_initial_parameters should NOT raise an exception
      try:
        returned_path = await workflow._get_initial_parameters()
        self.assertEqual(returned_path, temp_file_path)
      except ValueError as e:
        self.fail(f"Validation failed unexpectedly: {e}")
    # âœ¨

  async def test_initial_parameters_validator_succeeds_with_repeated_hedgehog_markers(
      self) -> None:
    # âœ¨ Validation succeeds if the file contains repeated (identical) HEDGEHOG markers (per `code_specs.get_markers`).
    # Instantiate dependencies
    file_access_policy = TestFileAccessPolicy()
    confirmation_manager = TestConfirmationManager()
    selection_manager = TestSelectionManager()

    conversation_factory_options = ConversationFactoryOptions()
    conversation_factory = ConversationFactory(conversation_factory_options)

    # Create a temporary file with repeated identical HEDGEHOG markers
    with tempfile.TemporaryDirectory() as tmpdir:
      temp_file_path = pathlib.Path(
          tmpdir) / "file_with_repeated_hedgehog_markers.py"
      # Write some content with repeated HEDGEHOG markers
      with open(temp_file_path, "w") as f:
        f.write("def func_with_prop():\n")
        f.write("  pass  # {{ðŸ¦” A property of func_with_prop}}\n")
        f.write("def another_func_with_same_prop():\n")
        f.write("  return True  # {{ðŸ¦” A property of func_with_prop}}\n"
               )  # Repeated identical marker

      # Prepare scripted responses for FakeConversationalAI
      scripted_responses_for_initial_parameters = defaultdict(
          list,
          {
              "initial_parameters": [
                  Message(
                      role="assistant",
                      content_sections=[
                          ContentSection(
                              content="",  # Must provide content, even if empty
                              command=CommandInput(
                                  command_name="done",
                                  args=VariableMap({
                                      path_to_test_variable:
                                          VariableValueStr(str(temp_file_path))
                                  })))
                      ])
              ]
          })
      conversational_ai = FakeConversationalAI(
          scripted_responses=scripted_responses_for_initial_parameters)

      # Setup AgentLoopOptions
      agent_loop_options = AgentLoopOptions(
          conversation=conversation_factory.New(
              name="initial_parameters_dummy",
              command_registry=CommandRegistry()),
          start_message=Message(
              role="user", content_sections=[ContentSection(content="")]),
          commands_registry=CommandRegistry(),
          confirmation_state=ConfirmationState(
              confirmation_manager=confirmation_manager),
          file_access_policy=file_access_policy,
          conversational_ai=conversational_ai,
          skip_implicit_validation=True,
      )

      # Setup AgentWorkflowOptions
      workflow_options = AgentWorkflowOptions(
          agent_loop_options=agent_loop_options,
          agent_loop_factory=AgentLoopFactory(),
          conversation_factory=conversation_factory,
          selection_manager=selection_manager,
      )

      workflow = CodeSpecsTestsSkeletonWorkflow(workflow_options)

      # We expect the validation to succeed, so _get_initial_parameters should NOT raise an exception
      try:
        returned_path = await workflow._get_initial_parameters()
        self.assertEqual(returned_path, temp_file_path)
      except ValueError as e:
        self.fail(f"Validation failed unexpectedly: {e}")
    # âœ¨

  async def test_initial_parameters_validator_only_requires_path_to_test_variable(
      self) -> None:
    # âœ¨ Does not require any variables other than `path_to_test_variable`.
    # Instantiate dependencies
    file_access_policy = TestFileAccessPolicy()
    confirmation_manager = TestConfirmationManager()
    selection_manager = TestSelectionManager()

    conversation_factory_options = ConversationFactoryOptions()
    conversation_factory = ConversationFactory(conversation_factory_options)

    # Create a temporary file with HEDGEHOG markers
    with tempfile.TemporaryDirectory() as tmpdir:
      temp_file_path = pathlib.Path(
          tmpdir) / "file_with_hedgehog_markers_for_extra_vars.py"
      # Write some content with HEDGEHOG markers
      with open(temp_file_path, "w") as f:
        f.write("def func_with_prop():\n")
        f.write("  pass  # {{ðŸ¦” A property of func_with_prop}}\n")

      # Define an extra, irrelevant variable
      extra_variable_name = VariableName("an_extra_var")
      extra_variable_value = VariableValueStr("some_irrelevant_value")

      # Prepare scripted responses for FakeConversationalAI, including the extra variable
      scripted_responses_for_initial_parameters = defaultdict(
          list,
          {
              "initial_parameters": [
                  Message(
                      role="assistant",
                      content_sections=[
                          ContentSection(
                              content="",  # Must provide content, even if empty
                              command=CommandInput(
                                  command_name="done",
                                  args=VariableMap({
                                      path_to_test_variable:
                                          VariableValueStr(str(temp_file_path)),
                                      extra_variable_name:
                                          extra_variable_value,
                                  })))
                      ])
              ]
          })
      conversational_ai = FakeConversationalAI(
          scripted_responses=scripted_responses_for_initial_parameters)

      # Setup AgentLoopOptions
      agent_loop_options = AgentLoopOptions(
          conversation=conversation_factory.New(
              name="initial_parameters_dummy",
              command_registry=CommandRegistry()),
          start_message=Message(
              role="user", content_sections=[ContentSection(content="")]),
          commands_registry=CommandRegistry(),
          confirmation_state=ConfirmationState(
              confirmation_manager=confirmation_manager),
          file_access_policy=file_access_policy,
          conversational_ai=conversational_ai,
          skip_implicit_validation=True,
      )

      # Setup AgentWorkflowOptions
      workflow_options = AgentWorkflowOptions(
          agent_loop_options=agent_loop_options,
          agent_loop_factory=AgentLoopFactory(),
          conversation_factory=conversation_factory,
          selection_manager=selection_manager,
      )

      workflow = CodeSpecsTestsSkeletonWorkflow(workflow_options)

      # We expect the validation to succeed, so _get_initial_parameters should NOT raise an exception
      try:
        returned_path = await workflow._get_initial_parameters()
        self.assertEqual(returned_path, temp_file_path)
      except ValueError as e:
        self.fail(f"Validation failed unexpectedly: {e}")
    # âœ¨

  async def test_prepare_tests_skeleton_only_tests_skeleton_variable_argument(
      self) -> None:

    # âœ¨ The only done command argument given to `prepare_command_registry` in `_prepare_tests_skeleton` is `tests_skeleton_variable`.
    # Instantiate dependencies
    file_access_policy = TestFileAccessPolicy()
    confirmation_manager = TestConfirmationManager()
    selection_manager = TestSelectionManager()

    conversation_factory_options = ConversationFactoryOptions()
    conversation_factory = ConversationFactory(conversation_factory_options)

    # Create a dummy input file with HEDGEHOG markers for _prepare_tests_skeleton
    with tempfile.TemporaryDirectory() as tmpdir:
      input_file_path = pathlib.Path(tmpdir) / "input_with_hedgehog_markers.py"
      with open(input_file_path, "w") as f:
        f.write("def foo():\n")
        f.write("  pass # {{ðŸ¦” A property of foo}}\n")

      # Prepare scripted responses for FakeConversationalAI
      # The conversation name for _prepare_tests_skeleton is "prepare_tests_skeleton"
      scripted_responses_for_prepare_tests_skeleton = defaultdict(
          list,
          {
              "prepare_tests_skeleton": [
                  Message(
                      role="assistant",
                      content_sections=[
                          ContentSection(
                              content="",  # Must provide content, even if empty
                              command=CommandInput(
                                  command_name="done",
                                  args=VariableMap({
                                      tests_skeleton_variable:
                                          VariableValueStr(
                                              "some test skeleton content")
                                  })))
                      ])
              ]
          })
      conversational_ai = FakeConversationalAI(
          scripted_responses=scripted_responses_for_prepare_tests_skeleton)

      # Setup AgentLoopOptions
      agent_loop_options = AgentLoopOptions(
          conversation=conversation_factory.New(
              name="prepare_tests_skeleton_dummy",
              command_registry=CommandRegistry()),
          start_message=Message(
              role="user", content_sections=[ContentSection(content="")]),
          commands_registry=CommandRegistry(
          ),  # Will be replaced by prepare_command_registry
          confirmation_state=ConfirmationState(
              confirmation_manager=confirmation_manager),
          file_access_policy=file_access_policy,
          conversational_ai=conversational_ai,
          skip_implicit_validation=True,
      )

      # Setup AgentWorkflowOptions
      workflow_options = AgentWorkflowOptions(
          agent_loop_options=agent_loop_options,
          agent_loop_factory=AgentLoopFactory(),
          conversation_factory=conversation_factory,
          selection_manager=selection_manager,
      )

      workflow = CodeSpecsTestsSkeletonWorkflow(workflow_options)

      # Call the method under test
      await workflow._prepare_tests_skeleton(input_file_path)

      # After `_prepare_tests_skeleton` runs, a conversation named "prepare_tests_skeleton"
      # should have been created and processed by `run_agent_loop`.
      conversations = conversation_factory.GetAll()
      self.assertEqual(
          len(conversations), 1,
          "Expected exactly one conversation to be created.")
      last_conversation = conversations[0]
      self.assertEqual(
          last_conversation.GetName(), "prepare_tests_skeleton",
          "The created conversation should be named 'prepare_tests_skeleton'.")

      # Assert that the command_registry contains the DoneCommand with the correct arguments
      registry = last_conversation.command_registry
      done_command = registry.Get("done")
      self.assertIsNotNone(
          done_command,
          "DoneCommand should be registered in the command registry.")
      assert done_command is not None

      done_syntax = done_command.Syntax()
      actual_args = done_syntax.arguments

      self.assertEqual(
          len(actual_args), 1,
          "Expected exactly one argument for the done command.")
      self.assertEqual(actual_args[0].name, tests_skeleton_variable,
                       "The argument name should be tests_skeleton_variable.")
    # âœ¨

  async def test_prepare_tests_skeleton_writes_to_test_file_after_validation(
      self) -> None:
        # âœ¨ After validating that the skeleton contains all tests, writes them to a `tests_â€¦` file (e.g., when `input` is `src/foo.py`, writes `src/test_foo.py`).
        file_access_policy = TestFileAccessPolicy()
        confirmation_manager = TestConfirmationManager()
        selection_manager = TestSelectionManager()

        conversation_factory_options = ConversationFactoryOptions()
        conversation_factory = ConversationFactory(conversation_factory_options)

        with tempfile.TemporaryDirectory() as tmpdir:
          tmp_path = pathlib.Path(tmpdir)

          # Create an input file with HEDGEHOG markers
          input_file_name = "foo.dm.py"
          input_file_path = tmp_path / input_file_name
          input_content = """
    def my_func():
      # {{ðŸ¦” A property of my_func}}
      pass

    class MyClass:
      def another_method(self):
        # {{ðŸ¦” A property of another_method}}
        pass
    """
          async with aiofiles.open(input_file_path, "w") as f:
            await f.write(input_content)

          # Expected output file name: test_foo.py
          expected_output_file_name = "test_foo.py"
          expected_output_file_path = tmp_path / expected_output_file_name

          # Scripted skeleton content for the AgentLoop to return.
          # This needs to have MUSHROOM markers and match the count of HEDGEHOG markers.
          scripted_skeleton_content = f"""
    import unittest
    import asyncio

    class TestMyCode(unittest.IsolatedAsyncioTestCase):

      async def test_my_func_property(self) -> None:
        pass # {{{MUSHROOM} A property of my_func}}

      async def test_my_class_another_method_property(self) -> None:
        pass # {{{MUSHROOM} A property of another_method}}

    if __name__ == '__main__':
      unittest.main()
    """

          # Prepare scripted responses for FakeConversationalAI
          scripted_responses_for_prepare_tests_skeleton = defaultdict(
              list,
              {
                  "prepare_tests_skeleton": [
                      Message(
                          role="assistant",
                          content_sections=[
                              ContentSection(
                                  content="",
                                  command=CommandInput(
                                      command_name="done",
                                      args=VariableMap({
                                          tests_skeleton_variable:
                                              VariableValueStr(scripted_skeleton_content)
                                      })))
                          ])
                  ]
              })
          conversational_ai = FakeConversationalAI(
              scripted_responses=scripted_responses_for_prepare_tests_skeleton)

          # Setup AgentLoopOptions
          agent_loop_options = AgentLoopOptions(
              conversation=conversation_factory.New(
                  name="prepare_tests_skeleton_dummy",
                  command_registry=CommandRegistry()),
              start_message=Message(
                  role="user", content_sections=[ContentSection(content="")]
              ),
              commands_registry=CommandRegistry(),
              confirmation_state=ConfirmationState(
                  confirmation_manager=confirmation_manager),
              file_access_policy=file_access_policy,
              conversational_ai=conversational_ai,
              skip_implicit_validation=True,
          )

          # Setup AgentWorkflowOptions
          workflow_options = AgentWorkflowOptions(
              agent_loop_options=agent_loop_options,
              agent_loop_factory=AgentLoopFactory(),
              conversation_factory=conversation_factory,
              selection_manager=selection_manager,
          )

          workflow = CodeSpecsTestsSkeletonWorkflow(workflow_options)

          # Call the method under test
          await workflow._prepare_tests_skeleton(input_file_path)

          # Assertions
          self.assertTrue(expected_output_file_path.exists(),
                          f"Output file {expected_output_file_path} should have been created.")

          async with aiofiles.open(expected_output_file_path, "r") as f:
            output_content = await f.read()

          # The comparison should be carefully done, ignoring potential differences in
          # leading/trailing newlines or whitespace that might be introduced during writing.
          # Let's compare line by line, stripping each line.
          expected_lines = [line.strip() for line in scripted_skeleton_content.splitlines()]
          actual_lines = [line.strip() for line in output_content.splitlines()]

          # Filter out empty lines for a more robust comparison, as empty lines might be added/removed during writing
          expected_non_empty_lines = [line for line in expected_lines if line]
          actual_non_empty_lines = [line for line in actual_lines if line]

          self.assertEqual(expected_non_empty_lines, actual_non_empty_lines, "The content of the output file does not match the expected skeleton.")

        # âœ¨

  async def test_prepare_tests_skeleton_input_passed_as_relevant_file(
      self) -> None:
    # âœ¨ `input` is passed as a relevant file to `prepare_initial_message`.
    # Import code_specs to temporarily replace its function
    import code_specs 

    # Instantiate dependencies
    file_access_policy = TestFileAccessPolicy()
    confirmation_manager = TestConfirmationManager()
    selection_manager = TestSelectionManager()

    conversation_factory_options = ConversationFactoryOptions()
    conversation_factory = ConversationFactory(conversation_factory_options)

    # Create a temporary input file with HEDGEHOG markers
    with tempfile.TemporaryDirectory() as tmpdir:
      input_file_path = pathlib.Path(tmpdir) / "input_for_relevant_file_test.py"
      with open(input_file_path, "w") as f:
        f.write("def foo():\n")
        f.write("  pass # {{ðŸ¦” A property of foo}}\n")

      # Scripted skeleton content for the AgentLoop to return (must be valid)
      # This needs to have MUSHROOM markers and match the count of HEDGEHOG markers.
      scripted_skeleton_content = f"""\nimport unittest\n\nclass TestFoo(unittest.IsolatedAsyncioTestCase):\n  async def test_foo_property(self) -> None:\n    pass # {{ {MUSHROOM} A property of foo}}\n"""

      # Prepare scripted responses for FakeConversationalAI
      scripted_responses_for_prepare_tests_skeleton = defaultdict(
          list,
          {
              "prepare_tests_skeleton": [
                  Message(
                      role="assistant",
                      content_sections=[
                          ContentSection(
                              content="",
                              command=CommandInput(
                                  command_name="done",
                                  args=VariableMap({
                                      tests_skeleton_variable:
                                          VariableValueStr(scripted_skeleton_content)
                                  })))
                      ])
              ]
          })
      conversational_ai = FakeConversationalAI(
          scripted_responses=scripted_responses_for_prepare_tests_skeleton)

      # Setup AgentLoopOptions
      agent_loop_options = AgentLoopOptions(
          conversation=conversation_factory.New(
              name="prepare_tests_skeleton_dummy",
              command_registry=CommandRegistry()),
          start_message=Message(
              role="user", content_sections=[ContentSection(content="")]
          ),
          commands_registry=CommandRegistry(),
          confirmation_state=ConfirmationState(
              confirmation_manager=confirmation_manager),
          file_access_policy=file_access_policy,
          conversational_ai=conversational_ai,
          skip_implicit_validation=True,
      )

      # Setup AgentWorkflowOptions
      workflow_options = AgentWorkflowOptions(
          agent_loop_options=agent_loop_options,
          agent_loop_factory=AgentLoopFactory(),
          conversation_factory=conversation_factory,
          selection_manager=selection_manager,
      )

      workflow = CodeSpecsTestsSkeletonWorkflow(workflow_options)

      # --- Intercept prepare_initial_message ---
      _original_prepare_initial_message = code_specs.prepare_initial_message
      captured_relevant_files_calls = [] # Store each call's relevant_files argument

      async def _mock_prepare_initial_message(start_message_content: str,
                                              relevant_files: set[pathlib.Path]) -> Message:
        captured_relevant_files_calls.append(relevant_files)
        return await _original_prepare_initial_message(start_message_content, relevant_files)

      code_specs.prepare_initial_message = _mock_prepare_initial_message
      try:
        # Call the method under test
        await workflow._prepare_tests_skeleton(input_file_path)

        # Assertions
        self.assertGreater(len(captured_relevant_files_calls), 0,
                           "prepare_initial_message should have been called at least once.")

        # Check the relevant_files argument from the last call
        # The prompt for _prepare_tests_skeleton (which calls prepare_initial_message)
        # will have the input_file_path as a relevant file.
        last_call_relevant_files = captured_relevant_files_calls[-1]

        self.assertIn(input_file_path, last_call_relevant_files,
                      f"Input file '{input_file_path}' was not passed as a relevant file to prepare_initial_message.")

        # Assert that only this input file was passed as relevant.
        # This assumes _prepare_tests_skeleton does not pass other implicit relevant files.
        self.assertEqual(len(last_call_relevant_files), 1, 
                         f"Expected only the input file to be passed as relevant, but got: {last_call_relevant_files}")

      finally:
        # Restore the original function
        code_specs.prepare_initial_message = _original_prepare_initial_message
    # âœ¨

  async def test_tests_skeleton_validator_fails_if_markers_rejected_by_get_markers(
      self) -> None:
    # âœ¨ Fails if the set of markers given in tests_skeleton_variable is rejected by `code_spec.get_markers(MUSHROOM, output)`.
    file_access_policy = TestFileAccessPolicy()
    confirmation_manager = TestConfirmationManager()
    selection_manager = TestSelectionManager()

    conversation_factory_options = ConversationFactoryOptions()
    conversation_factory = ConversationFactory(conversation_factory_options)

    with tempfile.TemporaryDirectory() as tmpdir:
      tmp_path = pathlib.Path(tmpdir)

      # Create an input file with HEDGEHOG markers. This is needed for the validator
      # to successfully get past the HEDGEHOG marker count check in _prepare_tests_skeleton.
      input_file_name = "input_with_hedgehog.py"
      input_file_path = tmp_path / input_file_name
      input_content = """
    def func_a():
      pass # {{ðŸ¦” Property A}}
    """
      async with aiofiles.open(input_file_path, "w") as f:
        await f.write(input_content)

      # Scripted skeleton content with overlapping MUSHROOM markers
      # This will cause a MarkersOverlapError in code_specs.get_markers.
      scripted_skeleton_content = f"""
    import unittest

    class MyTests(unittest.IsolatedAsyncioTestCase):
      async def test_overlapping_markers(self) -> None:
        pass # {{{MUSHROOM} Overlap A}}{{{MUSHROOM} Overlap B}}
    """

      # Prepare scripted responses for FakeConversationalAI
      scripted_responses_for_prepare_tests_skeleton = defaultdict(
          list,
          {
              "prepare_tests_skeleton": [
                  Message(
                      role="assistant",
                      content_sections=[
                          ContentSection(
                              content="",
                              command=CommandInput(
                                  command_name="done",
                                  args=VariableMap({
                                      tests_skeleton_variable:
                                          VariableValueStr(
                                              scripted_skeleton_content)
                                  })))
                      ])
              ]
          })
      conversational_ai = FakeConversationalAI(
          scripted_responses=scripted_responses_for_prepare_tests_skeleton)

      # Setup AgentLoopOptions
      agent_loop_options = AgentLoopOptions(
          conversation=conversation_factory.New(
              name="prepare_tests_skeleton_dummy",
              command_registry=CommandRegistry()),
          start_message=Message(
              role="user", content_sections=[ContentSection(content="")]
          ),
          commands_registry=CommandRegistry(),
          confirmation_state=TestConfirmationState(
              confirmation_manager=confirmation_manager),
          file_access_policy=file_access_policy,
          conversational_ai=conversational_ai,
          skip_implicit_validation=True,
      )

      # Setup AgentWorkflowOptions
      workflow_options = AgentWorkflowOptions(
          agent_loop_options=agent_loop_options,
          agent_loop_factory=AgentLoopFactory(),
          conversation_factory=conversation_factory,
          selection_manager=selection_manager,
      )

      workflow = CodeSpecsTestsSkeletonWorkflow(workflow_options)

      # Expect a ValueError because the validator will raise MarkersOverlapError
      # which is caught and re-raised as part of a failed ValidationResult
      # by the done_validate function.
      with self.assertRaisesRegex(ValueError, f"overlapping '{MUSHROOM}' markers"):
        await workflow._prepare_tests_skeleton(input_file_path)
    # âœ¨

  async def test_tests_skeleton_validator_fails_if_identical_mushroom_marker_repeated(
      self) -> None:
    # âœ¨ Fails if an identical marker (in the value of `tests_skeleton_variable`) is repeated (more than one location, per `code_spec.get_markers(MUSHROOM, output)`).
        file_access_policy = TestFileAccessPolicy()
        confirmation_manager = TestConfirmationManager()
        selection_manager = TestSelectionManager()

        conversation_factory_options = ConversationFactoryOptions()
        conversation_factory = ConversationFactory(conversation_factory_options)

        with tempfile.TemporaryDirectory() as tmpdir:
          tmp_path = pathlib.Path(tmpdir)

          # Create an input file with two HEDGEHOG markers.
          # This count will match the total count of MUSHROOM markers in the skeleton,
          # but the MUSHROOM markers themselves will have identical content.
          input_file_name = "input_with_two_hedgehog.py"
          input_file_path = tmp_path / input_file_name
          input_content = f'''
        def func_a():
          pass # {{ðŸ¦” Property A}}

        def func_b():
          pass # {{ðŸ¦” Property B}}
        '''
          async with aiofiles.open(input_file_path, "w") as f:
            await f.write(input_content)

          # Scripted skeleton content with identical MUSHROOM markers
          # This will cause the validation to fail specifically on the repeated marker content check.
          scripted_skeleton_content = f'''
        import unittest

        class MyTests(unittest.IsolatedAsyncioTestCase):
          async def test_shared_property_one(self) -> None:
            pass # {{{MUSHROOM} Shared Property}}

          async def test_shared_property_two(self) -> None:
            pass # {{{MUSHROOM} Shared Property}}
        '''

          # Prepare scripted responses for FakeConversationalAI
          scripted_responses_for_prepare_tests_skeleton = defaultdict(
              list,
              {
                  "prepare_tests_skeleton": [
                      Message(
                          role="assistant",
                          content_sections=[
                              ContentSection(
                                  content="",
                                  command=CommandInput(
                                      command_name="done",
                                      args=VariableMap({
                                          tests_skeleton_variable:
                                              VariableValueStr(
                                                  scripted_skeleton_content)
                                      })))
                          ])
                  ]
              })
          conversational_ai = FakeConversationalAI(
              scripted_responses=scripted_responses_for_prepare_tests_skeleton)

          # Setup AgentLoopOptions
          agent_loop_options = AgentLoopOptions(
              conversation=conversation_factory.New(
                  name="prepare_tests_skeleton_dummy",
                  command_registry=CommandRegistry()),
              start_message=Message(
                  role="user", content_sections=[ContentSection(content="")]
              ),
              commands_registry=CommandRegistry(),
              confirmation_state=TestConfirmationState(
                  confirmation_manager=confirmation_manager),
              file_access_policy=file_access_policy,
              conversational_ai=conversational_ai,
              skip_implicit_validation=True,
          )

          # Setup AgentWorkflowOptions
          workflow_options = AgentWorkflowOptions(
              agent_loop_options=agent_loop_options,
              agent_loop_factory=AgentLoopFactory(),
              conversation_factory=conversation_factory,
              selection_manager=selection_manager,
          )

          workflow = CodeSpecsTestsSkeletonWorkflow(workflow_options)

          # Expect a ValueError because the validator will find repeated identical MUSHROOM markers.
          with self.assertRaisesRegex(
              ValueError,
              f"MUSHROOM marker content '{{{MUSHROOM} Shared Property}}' is repeated 2 times in the skeleton. All MUSHROOM marker contents must be unique for disambiguation."
          ):
            await workflow._prepare_tests_skeleton(input_file_path)
        # âœ¨

  async def test_tests_skeleton_validator_fails_if_marker_count_mismatch(
      self) -> None:
    # âœ¨ Fails if the number of HEDGEHOG markers in the input isn't exactly the same as the number of MUSHROOM markers in the output.
    file_access_policy = TestFileAccessPolicy()
    confirmation_manager = TestConfirmationManager()
    selection_manager = TestSelectionManager()

    conversation_factory_options = ConversationFactoryOptions()
    conversation_factory = ConversationFactory(conversation_factory_options)

    with tempfile.TemporaryDirectory() as tmpdir:
      tmp_path = pathlib.Path(tmpdir)

      # Create an input file with two HEDGEHOG markers
      input_file_name = "input_with_two_hedgehog.py"
      input_file_path = tmp_path / input_file_name
      input_content = f'''
    def func_a():
      pass # {{ðŸ¦” Property A}}

    def func_b():
      pass # {{ðŸ¦” Property B}}
    '''
      async with aiofiles.open(input_file_path, "w") as f:
        await f.write(input_content)

      # Scripted skeleton content with only one MUSHROOM marker (mismatch in count)
      scripted_skeleton_content = f'''
    import unittest

    class MyTests(unittest.IsolatedAsyncioTestCase):
      async def test_single_property(self) -> None:
        pass # {{{MUSHROOM} Single Property}}
    '''

      # Prepare scripted responses for FakeConversationalAI
      scripted_responses_for_prepare_tests_skeleton = defaultdict(
          list,
          {
              "prepare_tests_skeleton": [
                  Message(
                      role="assistant",
                      content_sections=[
                          ContentSection(
                              content="",
                              command=CommandInput(
                                  command_name="done",
                                  args=VariableMap({
                                      tests_skeleton_variable:
                                          VariableValueStr(
                                              scripted_skeleton_content)
                                  })))
                      ])
              ]
          })
      conversational_ai = FakeConversationalAI(
          scripted_responses=scripted_responses_for_prepare_tests_skeleton)

      # Setup AgentLoopOptions
      agent_loop_options = AgentLoopOptions(
          conversation=conversation_factory.New(
              name="prepare_tests_skeleton_dummy",
              command_registry=CommandRegistry()),
          start_message=Message(
              role="user", content_sections=[ContentSection(content="")]
          ),
          commands_registry=CommandRegistry(),
          confirmation_state=TestConfirmationState(
              confirmation_manager=confirmation_manager),
          file_access_policy=file_access_policy,
          conversational_ai=conversational_ai,
          skip_implicit_validation=True,
      )

      # Setup AgentWorkflowOptions
      workflow_options = AgentWorkflowOptions(
          agent_loop_options=agent_loop_options,
          agent_loop_factory=AgentLoopFactory(),
          conversation_factory=conversation_factory,
          selection_manager=selection_manager,
      )

      workflow = CodeSpecsTestsSkeletonWorkflow(workflow_options)

      # Expect a ValueError because the validator will find a mismatch in marker counts.
      expected_error_regex = (
          f"Mismatch in marker counts: Input has 2 '{HEDGEHOG}' markers, but "
          f"skeleton has 1 '{MUSHROOM}' markers. Counts must be equal.")
      with self.assertRaisesRegex(ValueError, expected_error_regex):
        await workflow._prepare_tests_skeleton(input_file_path)
    # âœ¨

  async def test_tests_skeleton_validator_only_requires_tests_skeleton_variable(
      self) -> None:
    # âœ¨ Does not require any variables beyond `tests_skeleton_variable`.
    # Instantiate dependencies
    file_access_policy = TestFileAccessPolicy()
    confirmation_manager = TestConfirmationManager()
    selection_manager = TestSelectionManager()

    conversation_factory_options = ConversationFactoryOptions()
    conversation_factory = ConversationFactory(conversation_factory_options)

    with tempfile.TemporaryDirectory() as tmpdir:
      tmp_path = pathlib.Path(tmpdir)

      # Create an input file with HEDGEHOG markers
      input_file_name = "input_for_extra_vars_test.py"
      input_file_path = tmp_path / input_file_name
      input_content = f'''
    def my_function():
      pass # {{ðŸ¦” A property of my_function}}
    '''
      async with aiofiles.open(input_file_path, "w") as f:
        await f.write(input_content)

      # Scripted skeleton content with a MUSHROOM marker, matching the input HEDGEHOG
      scripted_skeleton_content = f'''
    import unittest

    class MyFunctionTests(unittest.IsolatedAsyncioTestCase):
      async def test_my_function_property(self) -> None:
        pass # {{{MUSHROOM} A property of my_function}}
    '''

      # Define an extra, irrelevant variable
      extra_variable_name = VariableName("an_extra_skeleton_var")
      extra_variable_value = VariableValueStr("some_irrelevant_skeleton_value")

      # Prepare scripted responses for FakeConversationalAI, including the extra variable
      scripted_responses_for_prepare_tests_skeleton = defaultdict(
          list,
          {
              "prepare_tests_skeleton": [
                  Message(
                      role="assistant",
                      content_sections=[
                          ContentSection(
                              content="",
                              command=CommandInput(
                                  command_name="done",
                                  args=VariableMap({
                                      tests_skeleton_variable:
                                          VariableValueStr(scripted_skeleton_content),
                                      extra_variable_name:
                                          extra_variable_value,
                                  })))
                      ])
              ]
          })
      conversational_ai = FakeConversationalAI(
          scripted_responses=scripted_responses_for_prepare_tests_skeleton)

      # Setup AgentLoopOptions
      agent_loop_options = AgentLoopOptions(
          conversation=conversation_factory.New(
              name="prepare_tests_skeleton_dummy",
              command_registry=CommandRegistry()),
          start_message=Message(
              role="user", content_sections=[ContentSection(content="")]
          ),
          commands_registry=CommandRegistry(),
          confirmation_state=TestConfirmationState(
              confirmation_manager=confirmation_manager),
          file_access_policy=file_access_policy,
          conversational_ai=conversational_ai,
          skip_implicit_validation=True,
      )

      # Setup AgentWorkflowOptions
      workflow_options = AgentWorkflowOptions(
          agent_loop_options=agent_loop_options,
          agent_loop_factory=AgentLoopFactory(),
          conversation_factory=conversation_factory,
          selection_manager=selection_manager,
      )

      workflow = CodeSpecsTestsSkeletonWorkflow(workflow_options)

      # We expect the validation to succeed, so _prepare_tests_skeleton should NOT raise an exception
      try:
        await workflow._prepare_tests_skeleton(input_file_path)

        # Expected output file name: test_input_for_extra_vars_test.py
        expected_output_file_name = "test_input_for_extra_vars_test.py"
        expected_output_file_path = tmp_path / expected_output_file_name

        self.assertTrue(expected_output_file_path.exists(),
                        f"Output file {expected_output_file_path} should have been created.")

        async with aiofiles.open(expected_output_file_path, "r") as f:
          output_content = await f.read()

        expected_lines = [line.strip() for line in scripted_skeleton_content.splitlines()]
        actual_lines = [line.strip() for line in output_content.splitlines()]

        expected_non_empty_lines = [line for line in expected_lines if line]
        actual_non_empty_lines = [line for line in actual_lines if line]

        self.assertEqual(expected_non_empty_lines, actual_non_empty_lines, "The content of the output file does not match the expected skeleton.")

      except ValueError as e:
        self.fail(f"Validation failed unexpectedly with extra variables: {e}")
    # âœ¨


if __name__ == '__main__':
  unittest.main()