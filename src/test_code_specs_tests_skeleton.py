# DO NOT EDIT. This file is automatically generated by Duende.
# DM validator:
#
# MYPYPATH=~/coding-agent/src mypy $DMPATH && $PYTHON -m pytest $DMPATH
#
# These tests have a few constraints:
#
# * Mock is NOT allowed in this code. These tests should let all the
#   dependencies  of CodeSpecsTestsSkeleton be used directly.
#
# * These tests are not allowed to implement BaseAgentLoop directly; instead,
#   they must always use AgentLoop and AgentLoopFactory.
#
# * These tests must NOT subclass AgentLoop nor AgentLoopFactory, nor mock any
#   of their methods.
#
# * These tests must NOT contain the ðŸ„ character anywhere (in order to avoid
#   possible clashes with Duende, since that is already interpreting markers).
#
# * If they need to get a conversation, these tests must get it from the
#   self.conversation_factory. They must NOT get it from the conversational_ai.

import aiofiles
from collections import defaultdict
import os
import pathlib
import re
import shutil
import tempfile
from typing import Callable, Awaitable, Any
import unittest

from agent_command import Argument, AgentCommand, CommandOutput, CommandInput, AgentCommand, ArgumentContentType, VariableMap, VariableName, VariableValue, VariableValueStr
from agent_loop import AgentLoop, AgentLoopFactory
from agent_loop_options import AgentLoopOptions
from agent_workflow_options import AgentWorkflowOptions
from code_specs import PathAndValidator, Validator, prepare_command_registry, prepare_initial_message, run_agent_loop, ValidationResult, MarkerChar, MarkersOverlapError, MarkerName
from code_specs_tests_skeleton import CodeSpecsTestsSkeletonWorkflow, tests_skeleton_variable, MUSHROOM, HEDGEHOG, path_to_test_variable
from command_registry import CommandRegistry
from confirmation import ConfirmationManager, ConfirmationState
from conversation import Conversation, ConversationId, ConversationFactory, ConversationFactoryOptions
from conversation_state import ConversationState
from conversational_ai import ConversationalAI
from conversational_ai_test_utils import FakeConversationalAIConversation, FakeConversationalAI
from done_command import DoneCommand
from file_access_policy import FileAccessPolicy
from message import ContentSection, Message
from selection_manager import SelectionManager


class TestFileAccessPolicy(FileAccessPolicy):

  def allow_access(self, path: str) -> bool:
    return True  # Allow all access for testing


class TestConfirmationState(ConfirmationState):

  async def RequireConfirmation(self, conversation_id: int,
                                prompt: str) -> str | None:
    return None  # Always confirm


class TestConfirmationManager(ConfirmationManager):

  async def RequireConfirmation(self, conversation_id: ConversationId,
                                message: str) -> str | None:
    return None  # Always confirm for tests


class TestSelectionManager(SelectionManager):
  pass  # Default implementation is fine for now


class TestCodeSpecsTestsSkeletonWorkflow(unittest.IsolatedAsyncioTestCase):

  def setUp(self):
    self.conversation_factory = ConversationFactory(
        ConversationFactoryOptions())

  def done_message_with_path_to_test(self, path: pathlib.Path) -> Message:
    """Returns a Message calling `done` with `path_to_test_variable`."""
    # âœ¨ done message with path to test
    return Message(
        role="assistant",
        content_sections=[
            ContentSection(
                content=f"Calling done command with {path_to_test_variable} = {path}",
                command=CommandInput(
                    command_name="done",
                    args=VariableMap(
                        {path_to_test_variable: VariableValueStr(str(path))})),
                summary=f"Done command for path: {path}")
        ])
    # âœ¨

  def write_path_to_test_and_return_done_message(
      self, contents: str) -> tuple[Message, pathlib.Path]:
    """Returns a Message calling `done` with `path_to_test_variable`.

    The contents are written to a temporary file; its path is given to
    `path_to_test_variable` and returned. Clean-up of the temporary file is
    scheduled.

    The returned messages can be given directly to a FakeConversationalAI's list
    of messages. That implies that role should be "assistant".
    """
    # âœ¨ write path to test
    f = tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.py')
    f.write(contents)
    f.close()
    tmp_path = pathlib.Path(f.name)
    self.addCleanup(os.remove, tmp_path)

    message = self.done_message_with_path_to_test(tmp_path)
    return message, tmp_path
    # âœ¨

  def done_message_for_tests_skeleton(self, skeleton_content: str) -> Message:
    """Returns a Message calling `done` with `tests_skeleton_variable`.

    The returned messages can be given directly to a FakeConversationalAI's list
    of messages. That implies that role should be "assistant".
    """
    # âœ¨ done message for skeleton
    return Message(
        role="assistant",
        content_sections=[
            ContentSection(
                content=f"Calling done command with {tests_skeleton_variable} = '...' ",
                command=CommandInput(
                    command_name="done",
                    args=VariableMap({
                        tests_skeleton_variable:
                            VariableValueStr(skeleton_content)
                    })),
                summary="Done command for tests skeleton")
        ])
    # âœ¨

  def get_valid_contents_with_hedgehog_markers(self) -> str:
    """Returns a file (contents) with valid `"{{"+HEDGEHOG+prop+"}}"` markers.

    The file contains two different non-overlapping markers. Does not actually
    write the file, just returns text contents.
    """

    # âœ¨ tmp file with markers
    return '''
    # Some code
    def foo():
        pass # {{ðŸ¦” property1}}

    # More code
    class Bar:
        def baz(self):
            return 1 # {{ðŸ¦” property2}}
    '''
    # âœ¨

  async def build_workflow(
      self, scripted_messages: dict[str, list[Message]]
  ) -> CodeSpecsTestsSkeletonWorkflow:
    """Sets up a CodeSpecTestsSkeletonWorkflow with fake objects.

    Sets option skip_implicit_validation to True.
    """
    # âœ¨ build workflow
    fake_conversational_ai = FakeConversationalAI(scripted_messages)

    # `conversation`, `start_message`, and `commands_registry` in AgentLoopOptions
    # are placeholders here, as they will be overridden by `run_agent_loop`
    # when it creates the actual AgentLoop instance for a specific conversation.
    dummy_conversation = self.conversation_factory.New(
        "dummy_conversation_for_options", CommandRegistry())
    dummy_message = Message(
        role="user", content_sections=[ContentSection(content="dummy")])
    empty_command_registry = CommandRegistry()

    test_confirmation_manager = TestConfirmationManager()
    test_confirmation_state = TestConfirmationState(
        confirmation_manager=test_confirmation_manager)

    agent_loop_options = AgentLoopOptions(
        conversation=dummy_conversation,
        start_message=dummy_message,
        commands_registry=empty_command_registry,
        confirmation_state=test_confirmation_state,
        file_access_policy=TestFileAccessPolicy(),
        conversational_ai=fake_conversational_ai,
        confirm_regex=None,
        skip_implicit_validation=True,  # Set to True as per the requirement
        validation_manager=None,
    )

    agent_loop_factory = AgentLoopFactory()

    agent_workflow_options = AgentWorkflowOptions(
        agent_loop_options=agent_loop_options,
        agent_loop_factory=agent_loop_factory,
        conversation_factory=self.conversation_factory,
        selection_manager=TestSelectionManager(),
        principle_paths=None,
        input_paths=None,
        original_task_prompt_content=None,
        confirm_done='',
        do_review=False,
        review_first=False,
    )

    return CodeSpecsTestsSkeletonWorkflow(agent_workflow_options)
    # âœ¨

  def filter_content_sections(
      self, predicate: Callable[[ContentSection],
                                bool]) -> list[ContentSection]:
    """Returns any content sections in any messages that match a predicate.

    Extracts the messages from self.conversation_factory."""
    # âœ¨ filter content sections
    matching_sections: list[ContentSection] = []
    for conversation in self.conversation_factory.GetAll():
      for message in conversation.GetMessagesList():
        for section in message.GetContentSections():
          if predicate(section):
            matching_sections.append(section)
    return matching_sections
    # âœ¨

  async def test_get_initial_parameters_only_path_to_test_variable_argument(
      self) -> None:
    # âœ¨ The only done command argument given to `prepare_command_registry` is `path_to_test_variable`.
    # 1. Prepare a valid file content with a HEDGEHOG marker using the helper.
    valid_file_content = self.get_valid_contents_with_hedgehog_markers()

    # 2. Use the helper to create a temporary file and the done message for it.
    done_message, tmp_path = self.write_path_to_test_and_return_done_message(
        valid_file_content)

    # 3. Script the FakeConversationalAI to use this done_message for the
    #    "initial_parameters" conversation.
    scripted_messages = {"initial_parameters": [done_message]}

    # 4. Build the workflow with the scripted messages.
    workflow = await self.build_workflow(scripted_messages)

    # 5. Run _get_initial_parameters. This will execute an agent loop,
    #    and the FakeConversationalAI will record the conversation.
    await workflow._get_initial_parameters()

    # 6. Iterate through all conversations in the factory to find the one with the matching name.
    initial_parameters_conversation = None
    for conv in self.conversation_factory.GetAll():
      if conv.GetName() == "initial_parameters":
        initial_parameters_conversation = conv
        break

    self.assertIsNotNone(
        initial_parameters_conversation,
        "Conversation 'initial_parameters' not found in factory.")

    # 7. Get the command registry from this conversation.
    # Assert that initial_parameters_conversation is not None before accessing its command_registry.
    if initial_parameters_conversation is not None:
      command_registry = initial_parameters_conversation.command_registry
      self.assertIsInstance(command_registry, CommandRegistry)

      # 8. Find the DoneCommand in the command registry.
      done_command = None
      for command in command_registry.GetCommands():
        if isinstance(command, DoneCommand):
          done_command = command
          break

      self.assertIsNotNone(done_command, "DoneCommand not found in registry.")
      # Ensure mypy is happy by checking that done_command is not None before using it.
      if done_command is not None:
        # 9. Assert that the DoneCommand has only `path_to_test_variable` as its argument.
        done_syntax_arguments = done_command.Syntax().arguments
        self.assertEqual(len(done_syntax_arguments), 1)
        self.assertEqual(done_syntax_arguments[0].name, path_to_test_variable)
    # âœ¨

  async def test_initial_parameters_validator_fails_if_file_cant_be_read(
      self) -> None:
    # âœ¨ Validation fails if the file can't be read.
    # 1. Create a path to a non-existent file.
    non_existent_path = pathlib.Path("/non/existent/path/to/test_file.py")

    # 2. Create a message for the non-existent file.
    non_existent_done_message = self.done_message_with_path_to_test(
        non_existent_path)

    # 3. Create a valid temporary file with HEDGEHOG markers and its done message.
    valid_file_content = self.get_valid_contents_with_hedgehog_markers()
    valid_done_message, valid_tmp_file_path = self.write_path_to_test_and_return_done_message(
        valid_file_content)

    # 4. Script the FakeConversationalAI to first issue a done command with the non-existent path,
    #    then, after validation failure, issue a done command with the valid path.
    scripted_messages = {
        "initial_parameters": [non_existent_done_message, valid_done_message]
    }

    # 5. Build the workflow with the scripted messages.
    workflow = await self.build_workflow(scripted_messages)

    # 6. Run _get_initial_parameters. It should now complete successfully
    #    because the second 'done' message in scripted_messages provides a valid path.
    returned_path = await workflow._get_initial_parameters()

    # 7. Assert that the returned path is the valid one.
    self.assertEqual(returned_path, valid_tmp_file_path)

    # 8. Verify that the conversation history contains an error message
    #    indicating the validation failure for the first (non-existent) path.
    #    The error message will be from the ArgumentType.PATH_INPUT's internal validation.
    expected_error_substring = f"Warning done: Argument {path_to_test_variable}: File not found: Value: {non_existent_path}"

    def predicate(section: ContentSection) -> bool:
      # The predicate checks for content sections that contain the expected error message.
      return expected_error_substring in section.content

    matching_error_sections = self.filter_content_sections(predicate)

    # Assert that at least one such error message was found. This indicates the validation failed and was reported.
    self.assertGreaterEqual(
        len(matching_error_sections), 1,
        f"Expected validation error message for path '{non_existent_path}' not found in conversation sections. Found: {matching_error_sections}"
    )
    # âœ¨

  async def test_initial_parameters_validator_fails_if_no_hedgehog_markers(
      self) -> None:
    # âœ¨ Validation fails if the file doesn't contain any HEDGEHOG markers (per `code_specs.get_markers`).
    # 1. Create a temporary file that is readable but *does not* contain any HEDGEHOG markers.
    no_hedgehog_content = """
    # This is a test file without any HEDGEHOG markers.
    def some_function():
        return 1

    class SomeClass:
        pass
    """
    # Use the new helper to create the file and the done message for it.
    no_hedgehog_done_message, no_hedgehog_path = self.write_path_to_test_and_return_done_message(
        no_hedgehog_content)

    # 2. Create a valid temporary file with HEDGEHOG markers to allow the workflow to eventually succeed.
    valid_file_content = self.get_valid_contents_with_hedgehog_markers()
    valid_done_message, valid_path_from_message = self.write_path_to_test_and_return_done_message(
        valid_file_content)

    # 3. Script the FakeConversationalAI: first, try to validate the file without HEDGEHOG markers (expected to fail),
    #    then provide the valid file (expected to succeed).
    scripted_messages = {
        "initial_parameters": [
            no_hedgehog_done_message,
            valid_done_message,
        ]
    }

    # 4. Build the workflow with the scripted messages.
    workflow = await self.build_workflow(scripted_messages)

    # 5. Run _get_initial_parameters. It should now complete successfully
    #    because the second 'done' message in scripted_messages provides a valid path.
    returned_path = await workflow._get_initial_parameters()

    # 6. Assert that the returned path is the valid one.
    self.assertEqual(returned_path, valid_path_from_message)

    # 7. Verify that the conversation history contains an error message
    #    indicating the validation failure for the file without HEDGEHOG markers.
    expected_error_substring = (
        f"Error: File '{no_hedgehog_path}' does not contain any '{HEDGEHOG}' markers."
    )

    def predicate(section: ContentSection) -> bool:
      return expected_error_substring in section.content

    matching_error_sections = self.filter_content_sections(predicate)

    # Assert that at least one such error message was found.
    self.assertGreaterEqual(
        len(matching_error_sections), 1,
        f"Expected validation error message for path '{no_hedgehog_path}' "
        f"not found in conversation sections. Found: {matching_error_sections}")
    # âœ¨

  async def test_initial_parameters_validator_succeeds_with_readable_file_and_hedgehog_markers(
      self) -> None:
    # âœ¨ Validation succeeds if the file can be read and contains HEDGEHOG markers (per `code_specs.get_markers`).
    # 1. Create a temporary file that is readable and contains HEDGEHOG markers.
    valid_file_content = self.get_valid_contents_with_hedgehog_markers()

    # 2. Use write_path_to_test_and_return_done_message to create a message with this content in a temporary file.
    done_message, valid_tmp_file_path = self.write_path_to_test_and_return_done_message(
        valid_file_content)

    # 3. Script the FakeConversationalAI to issue a done command with this valid path.
    scripted_messages = {"initial_parameters": [done_message]}

    # 4. Build the workflow with the scripted messages.
    workflow = await self.build_workflow(scripted_messages)

    # 5. Run _get_initial_parameters. It should complete successfully.
    returned_path = await workflow._get_initial_parameters()

    # 6. Assert that the returned path is the valid one.
    self.assertEqual(returned_path, valid_tmp_file_path)

    # 7. Verify that no validation error messages are present in the conversation sections.
    #    We check for sections that start with "Error: " or contain "Warning done:"
    #    which indicate validation failures.
    def predicate_for_errors(section: ContentSection) -> bool:
      return section.content.startswith(
          "Error: ") or "Warning done:" in section.content

    matching_error_sections = self.filter_content_sections(predicate_for_errors)
    self.assertEqual(
        len(matching_error_sections), 0,
        f"No validation error messages were expected, but found: {matching_error_sections}"
    )
    # âœ¨

  async def test_initial_parameters_validator_succeeds_with_repeated_hedgehog_markers(
      self) -> None:
    # âœ¨ Validation succeeds if the file contains repeated (identical) HEDGEHOG markers (per `code_specs.get_markers`).
    # 1. Create file content that contains repeated (identical) HEDGEHOG markers.
    repeated_hedgehog_content = """
            # Some code
            def func_a():
                pass # {{ðŸ¦” property1}}

            # More code
            def func_b():
                return 2 # {{ðŸ¦” property1}}
            """

    # 2. Use write_path_to_test_and_return_done_message to create a message with this content in a temporary file.
    done_message, repeated_markers_path = self.write_path_to_test_and_return_done_message(
        repeated_hedgehog_content)

    # 3. Script the FakeConversationalAI to issue a done command with this path.
    scripted_messages = {"initial_parameters": [done_message]}

    # 4. Build the workflow with the scripted messages.
    workflow = await self.build_workflow(scripted_messages)

    # 5. Run _get_initial_parameters. It should complete successfully.
    returned_path = await workflow._get_initial_parameters()

    # 6. Assert that the returned path is the correct one.
    self.assertEqual(returned_path, repeated_markers_path)

    # 7. Verify that no validation error messages are present in the conversation sections.
    def predicate_for_errors(section: ContentSection) -> bool:
      return section.content.startswith(
          "Error: ") or "Warning done:" in section.content

    matching_error_sections = self.filter_content_sections(predicate_for_errors)
    self.assertEqual(
        len(matching_error_sections), 0,
        f"No validation error messages were expected, but found: {matching_error_sections}"
    )
    # âœ¨

  async def test_initial_parameters_validator_only_requires_path_to_test_variable(
      self) -> None:
    # âœ¨ Does not require any variables other than `path_to_test_variable`.
    # 1. Prepare valid file content with HEDGEHOG markers using the helper.
    valid_file_content = self.get_valid_contents_with_hedgehog_markers()

    # 2. Use write_path_to_test_and_return_done_message to create a message with this content in a temporary file.
    #    This helper returns both the message and the path.
    done_message, valid_tmp_file_path = self.write_path_to_test_and_return_done_message(
        valid_file_content)

    # 3. Script the FakeConversationalAI to issue a done command with only the valid path.
    scripted_messages = {"initial_parameters": [done_message]}

    # 4. Build the workflow with the scripted messages.
    workflow = await self.build_workflow(scripted_messages)

    # 5. Run _get_initial_parameters. It should complete successfully.
    returned_path = await workflow._get_initial_parameters()

    # 6. Assert that the returned path is the valid one.
    self.assertEqual(returned_path, valid_tmp_file_path)

    # 7. Verify that no validation error messages are present in the conversation sections.
    def predicate_for_errors(section: ContentSection) -> bool:
      return section.content.startswith(
          "Error: ") or "Warning done:" in section.content

    matching_error_sections = self.filter_content_sections(predicate_for_errors)
    self.assertEqual(
        len(matching_error_sections), 0,
        f"No validation error messages were expected, but found: {matching_error_sections}"
    )
    # âœ¨

  async def test_prepare_tests_skeleton_only_tests_skeleton_variable_argument(
      self) -> None:
    # âœ¨ The only done command argument given to `prepare_command_registry` in `_prepare_tests_skeleton` is `tests_skeleton_variable`.
    # 1. Prepare a valid file content with HEDGEHOG markers. This file will be the input to _prepare_tests_skeleton.
    valid_file_content = ("# {{ðŸ¦” A test property}}"
                          "\ndef some_function():"
                          "\n    pass\n")

    # 2. Use the helper to create a temporary file and the initial done message.
    done_message_for_initial_params, tmp_input_path = self.write_path_to_test_and_return_done_message(
        valid_file_content)

    # 3. Define a valid skeleton content for the "prepare_tests_skeleton" conversation.
    #    This skeleton needs to have the correct number of MUSHROOM markers to pass validation.
    valid_skeleton_content = (
        "import unittest\n"
        "\n"
        "class MyTests(unittest.IsolatedAsyncioTestCase):\n"
        "  async def test_a_test_property(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " A test property}}\n"
        "\n"
        "if __name__ == '__main__':\n"
        "  unittest.main()\n")

    # 4. Create the done message for the "prepare_tests_skeleton" conversation.
    prepare_tests_skeleton_done_message = self.done_message_for_tests_skeleton(
        valid_skeleton_content)

    # 5. Script the FakeConversationalAI for both conversations.
    scripted_messages = {
        "initial_parameters": [done_message_for_initial_params],
        "prepare_tests_skeleton": [prepare_tests_skeleton_done_message]
    }

    # 6. Build the workflow with the scripted messages.
    workflow = await self.build_workflow(scripted_messages)

    # 7. Run the entire workflow. This will execute both _get_initial_parameters and _prepare_tests_skeleton.
    await workflow.run()

    # 8. Iterate through all conversations in the factory to find the one with the name "prepare_tests_skeleton".
    prepare_tests_skeleton_conversation = None
    for conv in self.conversation_factory.GetAll():
      if conv.GetName() == "prepare_tests_skeleton":
        prepare_tests_skeleton_conversation = conv
        break

    self.assertIsNotNone(
        prepare_tests_skeleton_conversation,
        "Conversation 'prepare_tests_skeleton' not found in factory.")

    # 9. Get the command registry from this conversation.
    if prepare_tests_skeleton_conversation is not None:
      command_registry = prepare_tests_skeleton_conversation.command_registry
      self.assertIsInstance(command_registry, CommandRegistry)

      # 10. Find the DoneCommand in the command registry.
      done_command = None
      for command in command_registry.GetCommands():
        if isinstance(command, DoneCommand):
          done_command = command
          break

      self.assertIsNotNone(done_command, "DoneCommand not found in registry.")
      if done_command is not None:
        # 11. Assert that the DoneCommand has only `tests_skeleton_variable` as its argument.
        done_syntax_arguments = done_command.Syntax().arguments
        self.assertEqual(len(done_syntax_arguments), 1)
        self.assertEqual(done_syntax_arguments[0].name, tests_skeleton_variable)
    # âœ¨

  async def test_prepare_tests_skeleton_writes_to_test_file_after_validation(
      self) -> None:
    # âœ¨ After validating that the skeleton contains all tests, writes them to a `tests_â€¦` file (e.g., when `input` is `src/foo.py`, writes `src/test_foo.py`).
    # 1. Test case: input file is 'src/foo.py' -> output file 'src/test_foo.py'
    input_file_content_py = '''
                # Some code
                def func_to_test_py():
                    pass # {{ðŸ¦” property for py file}}
                '''
    done_message_for_py_input, tmp_input_py_path = self.write_path_to_test_and_return_done_message(
        input_file_content_py)

    expected_skeleton_content_py = (
        "import unittest\n"
        "\n"
        "class TestFuncToTestPy(unittest.IsolatedAsyncioTestCase):\n"
        "  async def test_func_to_test_py_property(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " property for py file}}\n"
        "\n"
        "if __name__ == '__main__':\n"
        "  unittest.main()\n")
    # 2. Test case: input file is 'src/foo.dm.py' -> output file 'src/test_foo.py'
    input_file_content_dm_py = '''
                # Some code in a .dm.py file
                def func_to_test_dm_py():
                    pass # {{ðŸ¦” property for dm py file}}
                '''

    done_message_for_dm_py_input, tmp_input_dm_py_path = self.write_path_to_test_and_return_done_message(
        input_file_content_dm_py)

    expected_skeleton_content_dm_py = (
        "import unittest\n"
        "\n"
        "class TestFuncToTestDmPy(unittest.IsolatedAsyncioTestCase):\n"
        "  async def test_func_to_test_dm_py_property(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " property for dm py file}}\n"
        "\n"
        "if __name__ == '__main__':\n"
        "  unittest.main()\n")

    # Scripted messages for the first workflow run (.py input)
    scripted_messages_py = {
        "initial_parameters": [done_message_for_py_input],
        "prepare_tests_skeleton": [
            self.done_message_for_tests_skeleton(expected_skeleton_content_py)
        ]
    }

    # Build and run the workflow for .py input
    workflow_py = await self.build_workflow(scripted_messages_py)
    await workflow_py.run()

    # Verify the output file for .py input
    output_py_file_name = f"test_{tmp_input_py_path.stem}{tmp_input_py_path.suffix}"
    expected_output_py_path = tmp_input_py_path.parent / output_py_file_name

    self.assertTrue(
        expected_output_py_path.exists(),
        f"Output file {expected_output_py_path} was not created for .py input.")

    async with aiofiles.open(expected_output_py_path, mode='r') as f:
      actual_output_content_py = await f.read()

    self.assertEqual(
        actual_output_content_py.strip(), expected_skeleton_content_py.strip(),
        "The content of the generated test file for .py input does not match the expected skeleton."
    )

    # Scripted messages for the second workflow run (.dm.py input)
    scripted_messages_dm_py = {
        "initial_parameters": [done_message_for_dm_py_input],
        "prepare_tests_skeleton": [
            self.done_message_for_tests_skeleton(
                expected_skeleton_content_dm_py)
        ]
    }

    # Build and run the workflow for .dm.py input
    workflow_dm_py = await self.build_workflow(scripted_messages_dm_py)
    await workflow_dm_py.run()

    # Verify the output file for .dm.py input
    output_dm_py_file_name = f"test_{tmp_input_dm_py_path.stem.replace('.dm', '')}{tmp_input_dm_py_path.suffix}"
    expected_output_dm_py_path = tmp_input_dm_py_path.parent / output_dm_py_file_name

    self.assertTrue(
        expected_output_dm_py_path.exists(),
        f"Output file {expected_output_dm_py_path} was not created for .dm.py input."
    )

    async with aiofiles.open(expected_output_dm_py_path, mode='r') as f:
      actual_output_content_dm_py = await f.read()

    self.assertEqual(
        actual_output_content_dm_py.strip(),
        expected_skeleton_content_dm_py.strip(),
        "The content of the generated test file for .dm.py input does not match the expected skeleton."
    )
    # âœ¨

  async def test_prepare_tests_skeleton_input_passed_as_relevant_file(
      self) -> None:

    # âœ¨ `input` is passed as a relevant file to `prepare_initial_message`.
    # 1. Create a temporary input file.
    input_file_content = """
    # Some code.
    def foo():
        pass # {{ðŸ¦” property for testing relevant files}}
    """
    # Use the helper to create a temporary file and the initial done message.
    done_message_for_initial_params, tmp_input_path = self.write_path_to_test_and_return_done_message(
        input_file_content)

    # 2. Script FakeConversationalAI.
    #    First, for _get_initial_parameters to provide the input file.
    #    Second, for _prepare_tests_skeleton to provide a dummy skeleton (to allow it to complete).
    scripted_messages = {
        "initial_parameters": [done_message_for_initial_params],
        "prepare_tests_skeleton": [
            self.done_message_for_tests_skeleton("def test_dummy(): pass # {{" +
                                                 str(MUSHROOM) + " dummy}}")
        ]
    }

    # 3. Build the workflow.
    workflow = await self.build_workflow(scripted_messages)

    # 4. Run the workflow. This will execute both _get_initial_parameters and _prepare_tests_skeleton.
    await workflow.run()

    # 5. Iterate through all conversations in the factory to find the one with the name "prepare_tests_skeleton".
    found_conversation: Conversation | None = None
    for conv in self.conversation_factory.GetAll():
      if conv.GetName() == "prepare_tests_skeleton":
        found_conversation = conv
        break

    self.assertIsNotNone(
        found_conversation,
        "Conversation 'prepare_tests_skeleton' not found in factory.")

    if found_conversation is not None:
      # 6. Get the list of messages in the found conversation.
      messages_list = found_conversation.GetMessagesList()

      # The initial message from the agent should be the first message in the conversation.
      # This is the 'start_message' that was prepared by prepare_initial_message.
      initial_message_from_agent: Message | None = None
      if messages_list:
        initial_message_from_agent = messages_list[0]

      self.assertIsNotNone(
          initial_message_from_agent,
          "Initial message from agent for 'prepare_tests_skeleton' conversation not found."
      )

      if initial_message_from_agent is not None:
        # Check if any ContentSection contains the relevant file information.
        relevant_file_found = False
        expected_content_start = f"File '{tmp_input_path}' follows:"

        for section in initial_message_from_agent.GetContentSections():
          if section.content.startswith(expected_content_start):
            relevant_file_found = True
            self.assertIn(input_file_content.strip(), section.content)
            break

        self.assertTrue(
            relevant_file_found,
            "The 'input' file content was not found as a relevant file section in the initial message for _prepare_tests_skeleton."
        )
      else:
        self.fail(
            "Logical error: initial_message_from_agent should not be None after assertion."
        )
    else:
      self.fail(
          "Logical error: found_conversation should not be None after assertion."
      )
    # âœ¨

  async def test_tests_skeleton_validator_fails_if_markers_rejected_by_get_markers(
      self) -> None:
    # âœ¨ Fails if the set of markers given in tests_skeleton_variable is rejected by `code_spec.get_markers(MUSHROOM, output)`.
    # 1. Create a temporary input file with HEDGEHOG markers asynchronously.
    valid_hedgehog_content = self.get_valid_contents_with_hedgehog_markers()
    # Use the helper to create the temporary file and the initial done message.
    initial_parameters_done_message, tmp_input_file_path = self.write_path_to_test_and_return_done_message(
        valid_hedgehog_content)
    # This file has 2 HEDGEHOG markers.

    # 2. Define an invalid skeleton content that causes MarkersOverlapError.
    #    This skeleton has two MUSHROOM markers on the same line.
    invalid_skeleton_content = (
        "import unittest\n"
        "\n"
        "class MyTests(unittest.IsolatedAsyncioTestCase):\n"
        "  async def test_overlapping_markers_1(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " marker_overlap_1}}{{" +
        str(MUSHROOM) + " marker_overlap_2}}\n"
        "  async def test_overlapping_markers_2(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " another_valid_marker}}\n"
        "\n"
        "if __name__ == '__main__':\n"
        "  unittest.main()\n")

    # 3. Define a valid skeleton content that passes all validations.
    #    It should have the same number of MUSHROOM markers (2) as HEDGEHOG markers in the input.
    valid_skeleton_content = (
        "import unittest\n"
        "\n"
        "class MyTests(unittest.IsolatedAsyncioTestCase):\n"
        "  async def test_valid_marker_1(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " valid_marker_1}}\n"
        "  async def test_valid_marker_2(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " valid_marker_2}}\n"
        "\n"
        "if __name__ == '__main__':\n"
        "  unittest.main()\n")

    # 4. Script FakeConversationalAI.
    scripted_messages = {
        "initial_parameters": [initial_parameters_done_message],
        "prepare_tests_skeleton": [
            # First attempt: invalid skeleton
            self.done_message_for_tests_skeleton(invalid_skeleton_content),
            # Second attempt: valid skeleton to allow the workflow to complete
            self.done_message_for_tests_skeleton(valid_skeleton_content)
        ]
    }

    # 5. Build and run the workflow.
    workflow = await self.build_workflow(scripted_messages)
    await workflow.run()

    # 6. Verify that an error message related to MarkersOverlapError is present.
    expected_error_substring_part1 = "Generated skeleton contains overlapping 'ðŸ„' markers:"
    expected_error_substring_part2 = "Error: "

    def predicate_for_errors(section: ContentSection) -> bool:
      return section.content.startswith(
          expected_error_substring_part2
      ) and expected_error_substring_part1 in section.content

    matching_error_sections = self.filter_content_sections(predicate_for_errors)

    self.assertGreaterEqual(
        len(matching_error_sections), 1,
        f"Expected validation error message for overlapping MUSHROOM markers not found in conversation sections. Found: {matching_error_sections}"
    )

    # 7. Optionally, verify that the output file created is from the valid skeleton.
    #    This implies that the workflow recovered from the validation error and proceeded.
    output_file_name = f"test_{tmp_input_file_path.stem}{tmp_input_file_path.suffix}"
    expected_output_path = tmp_input_file_path.parent / output_file_name

    self.assertTrue(
        expected_output_path.exists(),
        f"Output file {expected_output_path} was not created after valid skeleton was provided."
    )

    async with aiofiles.open(expected_output_path, mode='r') as f:
      actual_output_content = await f.read()

    self.assertEqual(
        actual_output_content.strip(), valid_skeleton_content.strip(),
        "The content of the generated test file does not match the expected valid skeleton."
    )
    # âœ¨

  async def test_tests_skeleton_validator_fails_if_identical_mushroom_marker_repeated(
      self) -> None:
    # âœ¨ Fails if an identical marker (in the value of `tests_skeleton_variable`) is repeated (more than one location, per `code_spec.get_markers(MUSHROOM, output)`).
    # 1. Prepare a valid file content with HEDGEHOG markers using the helper.
    valid_file_content = self.get_valid_contents_with_hedgehog_markers()

    # Create a message that simulates the user providing a valid path.
    # The write_path_to_test_and_return_done_message helper writes the content to a temporary file
    # and returns a Message with the path in path_to_test_variable, along with the temporary path.
    done_message_for_initial_params, tmp_input_file_path = self.write_path_to_test_and_return_done_message(
        valid_file_content)

    # This file has 2 HEDGEHOG markers.

    # 2. Define an invalid skeleton content that causes a repeated MUSHROOM marker.
    #    This skeleton has the same MUSHROOM marker name used twice.
    invalid_skeleton_content = (
        "import unittest\n"
        "\n"
        "class MyTests(unittest.IsolatedAsyncioTestCase):\n"
        "  async def test_repeated_marker_1(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " repeated_marker_name}}\n"
        "  async def test_repeated_marker_2(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " repeated_marker_name}}\n"
        "\n"
        "if __name__ == '__main__':\n"
        "  unittest.main()\n")

    # 3. Define a valid skeleton content that passes all validations.
    #    It should have the same number of MUSHROOM markers (2) as HEDGEHOG markers in the input,
    #    and no repeated marker names.
    valid_skeleton_content = (
        "import unittest\n"
        "\n"
        "class MyTests(unittest.IsolatedAsyncioTestCase):\n"
        "  async def test_unique_marker_1(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " unique_marker_name_1}}\n"
        "  async def test_unique_marker_2(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " unique_marker_name_2}}\n"
        "\n"
        "if __name__ == '__main__':\n"
        "  unittest.main()\n")

    # 4. Script FakeConversationalAI.
    scripted_messages = {
        "initial_parameters": [done_message_for_initial_params],
        "prepare_tests_skeleton": [
            # First attempt: invalid skeleton with repeated MUSHROOM marker
            self.done_message_for_tests_skeleton(invalid_skeleton_content),
            # Second attempt: valid skeleton to allow the workflow to complete
            self.done_message_for_tests_skeleton(valid_skeleton_content)
        ]
    }

    # 5. Build and run the workflow.
    workflow = await self.build_workflow(scripted_messages)
    await workflow.run()

    # 6. Verify that an error message related to repeated MUSHROOM markers is present.
    expected_error_prefix = "Error: "
    expected_error_substring_part1 = f"MUSHROOM marker content \'{{{str(MUSHROOM)} MarkerName(char=\'{str(MUSHROOM)}\', name=\'repeated_marker_name\')}}\' is repeated 2 times in the skeleton."

    def predicate_for_errors(section: ContentSection) -> bool:
      return (section.content.startswith(expected_error_prefix) and
              expected_error_substring_part1 in section.content)

    matching_error_sections = self.filter_content_sections(predicate_for_errors)

    self.assertGreaterEqual(
        len(matching_error_sections), 1,
        f"Expected validation error message for repeated MUSHROOM marker not found in conversation sections. Found: {matching_error_sections}"
    )

    # 7. Verify that the output file created is from the valid skeleton.
    #    This implies that the workflow recovered from the validation error and proceeded.
    output_file_name = f"test_{tmp_input_file_path.stem}{tmp_input_file_path.suffix}"
    expected_output_path = tmp_input_file_path.parent / output_file_name

    self.assertTrue(
        expected_output_path.exists(),
        f"Output file {expected_output_path} was not created after valid skeleton was provided."
    )

    async with aiofiles.open(expected_output_path, mode='r') as f:
      actual_output_content = await f.read()

    self.assertEqual(
        actual_output_content.strip(), valid_skeleton_content.strip(),
        "The content of the generated test file does not match the expected valid skeleton."
    )
    # âœ¨

  async def test_tests_skeleton_validator_fails_if_marker_count_mismatch(
      self) -> None:
    # âœ¨ Fails if the number of HEDGEHOG markers in the input isn't exactly the same as the number of MUSHROOM markers in the output.
    # 1. Prepare a valid file content with 2 HEDGEHOG markers.
    valid_file_content = self.get_valid_contents_with_hedgehog_markers()
    # Create a message that simulates the user providing a valid path.
    done_message_for_initial_params, tmp_input_file_path = self.write_path_to_test_and_return_done_message(
        valid_file_content)

    # This file has 2 HEDGEHOG markers.

    # 2. Define an invalid skeleton content with 1 MUSHROOM marker (mismatch).
    invalid_skeleton_content_one_mushroom = (
        "import unittest\n"
        "\n"
        "class MyTests(unittest.IsolatedAsyncioTestCase):\n"
        "  async def test_one_marker(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " one_marker}}\n"
        "\n"
        "if __name__ == '__main__':\n"
        "  unittest.main()\n")

    # 3. Define a valid skeleton content with 2 MUSHROOM markers (match).
    valid_skeleton_content_two_mushrooms = (
        "import unittest\n"
        "\n"
        "class MyTests(unittest.IsolatedAsyncioTestCase):\n"
        "  async def test_valid_marker_1(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " valid_marker_1}}\n"
        "  async def test_valid_marker_2(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " valid_marker_2}}\n"
        "\n"
        "if __name__ == '__main__':\n"
        "  unittest.main()\n")

    # 4. Script FakeConversationalAI.
    scripted_messages = {
        "initial_parameters": [done_message_for_initial_params],
        "prepare_tests_skeleton": [
            # First attempt: invalid skeleton with one MUSHROOM marker
            self.done_message_for_tests_skeleton(
                invalid_skeleton_content_one_mushroom),
            # Second attempt: valid skeleton to allow the workflow to complete
            self.done_message_for_tests_skeleton(
                valid_skeleton_content_two_mushrooms),
            # Add an empty message to allow the conversation to terminate gracefully
            Message(
                role="assistant", content_sections=[ContentSection(content="")])
        ]
    }
    # 5. Build and run the workflow.
    workflow = await self.build_workflow(scripted_messages)
    await workflow.run()

    # 6. Verify that an error message related to marker count mismatch is present.
    expected_error_prefix = "Error: "
    # Corrected to match the actual error message format
    expected_error_substring_part1 = (
        "Mismatch in marker counts: Input has 2 'ðŸ¦”' markers, but skeleton has 1 'ðŸ„' markers. "
        "Counts must be equal.")

    def predicate_for_errors(section: ContentSection) -> bool:
      return (section.content.startswith(expected_error_prefix) and
              expected_error_substring_part1 in section.content)

    matching_error_sections = self.filter_content_sections(predicate_for_errors)

    self.assertGreaterEqual(
        len(matching_error_sections), 1,
        "Expected validation error message for marker count mismatch not found "
        f"in conversation sections. Found: {matching_error_sections}")

    # 7. Verify that the output file created is from the valid skeleton.
    output_file_name = f"test_{tmp_input_file_path.stem}{tmp_input_file_path.suffix}"
    expected_output_path = tmp_input_file_path.parent / output_file_name

    self.assertTrue(
        expected_output_path.exists(),
        f"Output file {expected_output_path} was not created after valid skeleton was provided."
    )
    async with aiofiles.open(expected_output_path, mode='r') as f:
      actual_output_content = await f.read()
    self.assertEqual(
        actual_output_content.strip(),
        valid_skeleton_content_two_mushrooms.strip(),
        "The content of the generated test file does not match the expected valid skeleton."
    )
    # âœ¨

  async def test_tests_skeleton_validator_only_requires_tests_skeleton_variable(
      self) -> None:
    # âœ¨ Does not require any variables beyond `tests_skeleton_variable`.
    # 1. Create a temporary input file with HEDGEHOG markers asynchronously.
    valid_hedgehog_content = self.get_valid_contents_with_hedgehog_markers()
    # Use the helper to create the temporary file and the initial done message.
    initial_parameters_done_message, tmp_input_file_path = self.write_path_to_test_and_return_done_message(
        valid_hedgehog_content)
    # This file has 2 HEDGEHOG markers as per `get_valid_contents_with_hedgehog_markers`.

    # 2. Define a valid skeleton content. It should have 2 MUSHROOM markers
    #    to match the number of HEDGEHOG markers in the input,
    #    and no repeated or overlapping MUSHROOM markers.
    valid_skeleton_content = (
        "import unittest\n"
        "\n"
        "class MyTests(unittest.IsolatedAsyncioTestCase):\n"
        "  async def test_first_property(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " property1}}\n"
        "  async def test_second_property(self) -> None:\n"
        "    pass  # {{" + str(MUSHROOM) + " property2}}\n"
        "\n"
        "if __name__ == '__main__':\n"
        "  unittest.main()\n")

    # 3. Script FakeConversationalAI.
    scripted_messages = {
        "initial_parameters": [initial_parameters_done_message],
        "prepare_tests_skeleton": [
            # Provide the valid skeleton. This should pass as no other variables are required.
            self.done_message_for_tests_skeleton(valid_skeleton_content),
            # Add an empty message to allow the conversation to terminate gracefully
            Message(
                role="assistant",
                content_sections=[ContentSection(content="")]),
        ]
    }

    # 4. Build and run the workflow.
    workflow = await self.build_workflow(scripted_messages)
    await workflow.run()

    # 5. Verify that no validation error messages are present in the conversation sections.
    #    This confirms that only `tests_skeleton_variable` was needed and the validation passed.
    def predicate_for_errors(section: ContentSection) -> bool:
      return section.content.startswith(
          "Error: ") or "Warning done:" in section.content

    matching_error_sections = self.filter_content_sections(predicate_for_errors)
    self.assertEqual(
        len(matching_error_sections), 0,
        f"No validation error messages were expected, but found: {matching_error_sections}"
    )

    # 6. Optionally, verify that the output file was created with the valid skeleton content.
    output_file_name = f"test_{tmp_input_file_path.stem}{tmp_input_file_path.suffix}"
    expected_output_path = tmp_input_file_path.parent / output_file_name

    self.assertTrue(expected_output_path.exists(),
                    f"Output file {expected_output_path} was not created.")

    async with aiofiles.open(expected_output_path, mode='r') as f:
      actual_output_content = await f.read()

    self.assertEqual(
        actual_output_content.strip(), valid_skeleton_content.strip(),
        "The content of the generated test file does not match the expected valid skeleton."
    )

  # âœ¨


if __name__ == '__main__':
  unittest.main()
